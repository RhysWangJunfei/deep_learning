#AE training
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, UpSampling2D, BatchNormalization,Activation,MaxPool2D
encoder = Sequential()
# L1
encoder.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(32, 32, 3), activation='relu', padding='same'))
encoder.add(BatchNormalization())
encoder.add(Activation('relu'))
encoder.add(MaxPool2D(pool_size=(2,2)))
# L2
encoder.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='same'))
encoder.add(BatchNormalization())
encoder.add(Activation('relu'))
encoder.add(MaxPool2D(pool_size=(2,2)))


decoder = tf.keras.Sequential()
#L3
decoder.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='same'))
decoder.add(BatchNormalization())
decoder.add(Activation('relu'))
decoder.add(UpSampling2D(size=(2,2)))
#L4
decoder.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same'))
decoder.add(BatchNormalization())
decoder.add(Activation('relu'))
decoder.add(UpSampling2D(size=(2,2)))

#L5
decoder.add(Conv2D(filters=3, kernel_size=(3,3), activation='relu', padding='same'))
decoder.add(BatchNormalization())
decoder.add(Activation('relu'))

autoencoder = tf.keras.Sequential([encoder, decoder])
autoencoder.compile(loss='mse', optimizer='adam')

# this model maps an input to its reconstruction
history = autoencoder.fit(trainset, trainset,
                epochs=300,
                batch_size=512,
                shuffle=True,
                validation_data=(cvset, cvset))
