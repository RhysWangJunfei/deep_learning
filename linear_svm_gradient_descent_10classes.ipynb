{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear_svm_gradient_descent_10classes",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPvkBM18Pqlw3JkG5+mY+av",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RhysWangJunfei/deep_learning/blob/master/linear_svm_gradient_descent_10classes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFe3hwApRkp8"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lQFhUBBRs_J"
      },
      "source": [
        "'''functions'''\n",
        "def combinations(lst, n):   \n",
        "    if n == 0: \n",
        "        return [[]]  \n",
        "    l =[] \n",
        "    for i in range(0, len(lst)):      \n",
        "        m = lst[i] \n",
        "        remLst = lst[i + 1:] \n",
        "          \n",
        "        for p in combinations(remLst, n-1): \n",
        "            l.append([m]+p)           \n",
        "    return l \n",
        "\n",
        "def scaling(dataX):\n",
        "    min_value=0\n",
        "    max_value=255\n",
        "    scaled_dataX = (dataX-min_value)/(max_value-min_value)\n",
        "    return scaled_dataX\n",
        "\n",
        "def cost_function(w,batch_x,batch_y,b,c):\n",
        "    hyp = np.dot(batch_x,w)+b\n",
        "    res = 1-hyp\n",
        "    res[res<0]=0  \n",
        "    hinge = np.mean(res,axis=0)\n",
        "    cost = 0.5*np.dot(w.T,w)+c*hinge\n",
        "    return cost\n",
        "\n",
        "def get_gradient(w,batch_x,batch_y,b):\n",
        "    error_w = np.zeros([batch_size,784])\n",
        "    error_b = np.zeros(batch_y.shape)\n",
        "    cond = 1-batch_y.reshape([-1,1])*(np.dot(batch_x,w)+b)\n",
        "    cond = cond.flatten()\n",
        "    if np.sum(cond<=0)>0:\n",
        "        error_w[cond<=0,:]=w.T\n",
        "    if np.sum(cond>0)>0:\n",
        "        error_w[cond>0,:]=w.T-batch_y[cond>0].reshape([-1,1])*batch_x[cond>0,:]\n",
        "        error_b[cond>0]=-batch_y[cond>0]\n",
        "    dw = np.mean(error_w,axis=0)\n",
        "    db = np.mean(error_b)\n",
        "    return dw,db\n",
        "\n",
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h6BWyexSI_x",
        "outputId": "cfa2e757-77a2-4304-cdd7-c6283ddc065f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "'''Data Preparation'''\n",
        "(x_train, y_train), (x_test, y_test)=tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
        "\n",
        "scaled_x_train = scaling(x_train)\n",
        "scaled_x_test = scaling(x_test)\n",
        "\n",
        "class_labels = np.arange(0,10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYYVpjpqR9_G",
        "outputId": "eeceaeb4-f0c6-40c1-d5ec-ccc1c8348611",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "'''Model Training'''\n",
        "#We can get 10*9/2=45 different combinations\n",
        "pairs = combinations(class_labels,2)\n",
        "loss_list = []\n",
        "model_list = []\n",
        "\n",
        "for pair in pairs:\n",
        "    positive = pair[0]\n",
        "    negative = pair[1]\n",
        "    data_positive_negative=scaled_x_train[(y_train==positive)|(y_train==negative)].reshape([-1,784])\n",
        "    label_positive_negative=y_train[(y_train==positive)|(y_train==negative)].astype(int)\n",
        "    label_positive_negative[label_positive_negative==negative]=-1\n",
        "    label_positive_negative[label_positive_negative==positive]=1\n",
        "    w = np.ones([784,1])*0.1\n",
        "    b=0\n",
        "    c=0.5\n",
        "    batch_size = 512\n",
        "    ids = np.arange(0,label_positive_negative.shape[0])\n",
        "    alpha=0.01\n",
        "    iter = 3000\n",
        "    #svm_loss_list=[]\n",
        "    for i in range(iter):\n",
        "        np.random.shuffle(ids)\n",
        "        batch_ids = ids[0:batch_size]\n",
        "        batch_x = data_positive_negative[batch_ids,:].reshape([-1,784])\n",
        "        batch_y = label_positive_negative[batch_ids]\n",
        "        cost = cost_function(w,batch_x,batch_y,b,c)\n",
        "        dw,db = get_gradient(w,batch_x,batch_y,b)\n",
        "        w = w-alpha*(dw.reshape([-1,1]))\n",
        "        b = b-alpha*db\n",
        "        print('iteration: '+str(i))\n",
        "        print('loss is: '+str(cost))\n",
        "        #svm_loss_list.append(cost.flatten())\n",
        "    model_dict = {'weight':w, 'bias':b}\n",
        "    model_list.append(model_dict)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "loss is: [[0.71230276]]\n",
            "iteration: 501\n",
            "loss is: [[0.69136124]]\n",
            "iteration: 502\n",
            "loss is: [[0.67419395]]\n",
            "iteration: 503\n",
            "loss is: [[0.66958762]]\n",
            "iteration: 504\n",
            "loss is: [[0.66959965]]\n",
            "iteration: 505\n",
            "loss is: [[0.68923045]]\n",
            "iteration: 506\n",
            "loss is: [[0.71386194]]\n",
            "iteration: 507\n",
            "loss is: [[0.68025072]]\n",
            "iteration: 508\n",
            "loss is: [[0.69637707]]\n",
            "iteration: 509\n",
            "loss is: [[0.69719315]]\n",
            "iteration: 510\n",
            "loss is: [[0.67043534]]\n",
            "iteration: 511\n",
            "loss is: [[0.67440798]]\n",
            "iteration: 512\n",
            "loss is: [[0.70073105]]\n",
            "iteration: 513\n",
            "loss is: [[0.65566869]]\n",
            "iteration: 514\n",
            "loss is: [[0.67886424]]\n",
            "iteration: 515\n",
            "loss is: [[0.68912439]]\n",
            "iteration: 516\n",
            "loss is: [[0.66649729]]\n",
            "iteration: 517\n",
            "loss is: [[0.66218761]]\n",
            "iteration: 518\n",
            "loss is: [[0.65986161]]\n",
            "iteration: 519\n",
            "loss is: [[0.65817643]]\n",
            "iteration: 520\n",
            "loss is: [[0.65073202]]\n",
            "iteration: 521\n",
            "loss is: [[0.65932238]]\n",
            "iteration: 522\n",
            "loss is: [[0.66405646]]\n",
            "iteration: 523\n",
            "loss is: [[0.71879074]]\n",
            "iteration: 524\n",
            "loss is: [[0.67698376]]\n",
            "iteration: 525\n",
            "loss is: [[0.67135167]]\n",
            "iteration: 526\n",
            "loss is: [[0.68676541]]\n",
            "iteration: 527\n",
            "loss is: [[0.66885087]]\n",
            "iteration: 528\n",
            "loss is: [[0.68793861]]\n",
            "iteration: 529\n",
            "loss is: [[0.67446903]]\n",
            "iteration: 530\n",
            "loss is: [[0.7012095]]\n",
            "iteration: 531\n",
            "loss is: [[0.70736932]]\n",
            "iteration: 532\n",
            "loss is: [[0.72120971]]\n",
            "iteration: 533\n",
            "loss is: [[0.69146923]]\n",
            "iteration: 534\n",
            "loss is: [[0.67092564]]\n",
            "iteration: 535\n",
            "loss is: [[0.65392384]]\n",
            "iteration: 536\n",
            "loss is: [[0.71780229]]\n",
            "iteration: 537\n",
            "loss is: [[0.71895358]]\n",
            "iteration: 538\n",
            "loss is: [[0.67133889]]\n",
            "iteration: 539\n",
            "loss is: [[0.68519606]]\n",
            "iteration: 540\n",
            "loss is: [[0.70741583]]\n",
            "iteration: 541\n",
            "loss is: [[0.69494182]]\n",
            "iteration: 542\n",
            "loss is: [[0.6552698]]\n",
            "iteration: 543\n",
            "loss is: [[0.70024404]]\n",
            "iteration: 544\n",
            "loss is: [[0.68088093]]\n",
            "iteration: 545\n",
            "loss is: [[0.68155963]]\n",
            "iteration: 546\n",
            "loss is: [[0.66480195]]\n",
            "iteration: 547\n",
            "loss is: [[0.65092901]]\n",
            "iteration: 548\n",
            "loss is: [[0.68904538]]\n",
            "iteration: 549\n",
            "loss is: [[0.68830572]]\n",
            "iteration: 550\n",
            "loss is: [[0.69908651]]\n",
            "iteration: 551\n",
            "loss is: [[0.69991883]]\n",
            "iteration: 552\n",
            "loss is: [[0.69741601]]\n",
            "iteration: 553\n",
            "loss is: [[0.69113295]]\n",
            "iteration: 554\n",
            "loss is: [[0.71070817]]\n",
            "iteration: 555\n",
            "loss is: [[0.68852884]]\n",
            "iteration: 556\n",
            "loss is: [[0.68501473]]\n",
            "iteration: 557\n",
            "loss is: [[0.66346631]]\n",
            "iteration: 558\n",
            "loss is: [[0.70534736]]\n",
            "iteration: 559\n",
            "loss is: [[0.65445006]]\n",
            "iteration: 560\n",
            "loss is: [[0.68219258]]\n",
            "iteration: 561\n",
            "loss is: [[0.72266216]]\n",
            "iteration: 562\n",
            "loss is: [[0.67726195]]\n",
            "iteration: 563\n",
            "loss is: [[0.64073947]]\n",
            "iteration: 564\n",
            "loss is: [[0.66664985]]\n",
            "iteration: 565\n",
            "loss is: [[0.66366329]]\n",
            "iteration: 566\n",
            "loss is: [[0.67967712]]\n",
            "iteration: 567\n",
            "loss is: [[0.67023633]]\n",
            "iteration: 568\n",
            "loss is: [[0.68254464]]\n",
            "iteration: 569\n",
            "loss is: [[0.7325346]]\n",
            "iteration: 570\n",
            "loss is: [[0.64485402]]\n",
            "iteration: 571\n",
            "loss is: [[0.68823413]]\n",
            "iteration: 572\n",
            "loss is: [[0.67155389]]\n",
            "iteration: 573\n",
            "loss is: [[0.68817893]]\n",
            "iteration: 574\n",
            "loss is: [[0.66171898]]\n",
            "iteration: 575\n",
            "loss is: [[0.70003972]]\n",
            "iteration: 576\n",
            "loss is: [[0.67475187]]\n",
            "iteration: 577\n",
            "loss is: [[0.64444698]]\n",
            "iteration: 578\n",
            "loss is: [[0.69437301]]\n",
            "iteration: 579\n",
            "loss is: [[0.68560804]]\n",
            "iteration: 580\n",
            "loss is: [[0.65298253]]\n",
            "iteration: 581\n",
            "loss is: [[0.70673662]]\n",
            "iteration: 582\n",
            "loss is: [[0.66986779]]\n",
            "iteration: 583\n",
            "loss is: [[0.6722727]]\n",
            "iteration: 584\n",
            "loss is: [[0.69039758]]\n",
            "iteration: 585\n",
            "loss is: [[0.67657617]]\n",
            "iteration: 586\n",
            "loss is: [[0.70014623]]\n",
            "iteration: 587\n",
            "loss is: [[0.68018407]]\n",
            "iteration: 588\n",
            "loss is: [[0.70133588]]\n",
            "iteration: 589\n",
            "loss is: [[0.71027732]]\n",
            "iteration: 590\n",
            "loss is: [[0.69801378]]\n",
            "iteration: 591\n",
            "loss is: [[0.69251362]]\n",
            "iteration: 592\n",
            "loss is: [[0.66536982]]\n",
            "iteration: 593\n",
            "loss is: [[0.70078405]]\n",
            "iteration: 594\n",
            "loss is: [[0.6657277]]\n",
            "iteration: 595\n",
            "loss is: [[0.66719659]]\n",
            "iteration: 596\n",
            "loss is: [[0.67492284]]\n",
            "iteration: 597\n",
            "loss is: [[0.64932245]]\n",
            "iteration: 598\n",
            "loss is: [[0.67877584]]\n",
            "iteration: 599\n",
            "loss is: [[0.68821948]]\n",
            "iteration: 600\n",
            "loss is: [[0.70180351]]\n",
            "iteration: 601\n",
            "loss is: [[0.70005819]]\n",
            "iteration: 602\n",
            "loss is: [[0.69354892]]\n",
            "iteration: 603\n",
            "loss is: [[0.67287651]]\n",
            "iteration: 604\n",
            "loss is: [[0.70596137]]\n",
            "iteration: 605\n",
            "loss is: [[0.65178628]]\n",
            "iteration: 606\n",
            "loss is: [[0.68143026]]\n",
            "iteration: 607\n",
            "loss is: [[0.6413808]]\n",
            "iteration: 608\n",
            "loss is: [[0.66421558]]\n",
            "iteration: 609\n",
            "loss is: [[0.67837457]]\n",
            "iteration: 610\n",
            "loss is: [[0.7314672]]\n",
            "iteration: 611\n",
            "loss is: [[0.68564824]]\n",
            "iteration: 612\n",
            "loss is: [[0.70212895]]\n",
            "iteration: 613\n",
            "loss is: [[0.65979587]]\n",
            "iteration: 614\n",
            "loss is: [[0.71226347]]\n",
            "iteration: 615\n",
            "loss is: [[0.67121691]]\n",
            "iteration: 616\n",
            "loss is: [[0.71858095]]\n",
            "iteration: 617\n",
            "loss is: [[0.71818998]]\n",
            "iteration: 618\n",
            "loss is: [[0.64828624]]\n",
            "iteration: 619\n",
            "loss is: [[0.66767384]]\n",
            "iteration: 620\n",
            "loss is: [[0.68945139]]\n",
            "iteration: 621\n",
            "loss is: [[0.67262461]]\n",
            "iteration: 622\n",
            "loss is: [[0.68265558]]\n",
            "iteration: 623\n",
            "loss is: [[0.66657733]]\n",
            "iteration: 624\n",
            "loss is: [[0.66153388]]\n",
            "iteration: 625\n",
            "loss is: [[0.71919724]]\n",
            "iteration: 626\n",
            "loss is: [[0.74265862]]\n",
            "iteration: 627\n",
            "loss is: [[0.68314349]]\n",
            "iteration: 628\n",
            "loss is: [[0.66120756]]\n",
            "iteration: 629\n",
            "loss is: [[0.70711407]]\n",
            "iteration: 630\n",
            "loss is: [[0.68349927]]\n",
            "iteration: 631\n",
            "loss is: [[0.70380816]]\n",
            "iteration: 632\n",
            "loss is: [[0.71351212]]\n",
            "iteration: 633\n",
            "loss is: [[0.64009815]]\n",
            "iteration: 634\n",
            "loss is: [[0.72157977]]\n",
            "iteration: 635\n",
            "loss is: [[0.71121635]]\n",
            "iteration: 636\n",
            "loss is: [[0.6782758]]\n",
            "iteration: 637\n",
            "loss is: [[0.70604675]]\n",
            "iteration: 638\n",
            "loss is: [[0.7159753]]\n",
            "iteration: 639\n",
            "loss is: [[0.68310391]]\n",
            "iteration: 640\n",
            "loss is: [[0.71878141]]\n",
            "iteration: 641\n",
            "loss is: [[0.67057778]]\n",
            "iteration: 642\n",
            "loss is: [[0.70557009]]\n",
            "iteration: 643\n",
            "loss is: [[0.69824335]]\n",
            "iteration: 644\n",
            "loss is: [[0.68551112]]\n",
            "iteration: 645\n",
            "loss is: [[0.70458785]]\n",
            "iteration: 646\n",
            "loss is: [[0.67542223]]\n",
            "iteration: 647\n",
            "loss is: [[0.72317982]]\n",
            "iteration: 648\n",
            "loss is: [[0.68807669]]\n",
            "iteration: 649\n",
            "loss is: [[0.63838544]]\n",
            "iteration: 650\n",
            "loss is: [[0.71482621]]\n",
            "iteration: 651\n",
            "loss is: [[0.63815938]]\n",
            "iteration: 652\n",
            "loss is: [[0.68937471]]\n",
            "iteration: 653\n",
            "loss is: [[0.69361489]]\n",
            "iteration: 654\n",
            "loss is: [[0.694092]]\n",
            "iteration: 655\n",
            "loss is: [[0.66718341]]\n",
            "iteration: 656\n",
            "loss is: [[0.67356151]]\n",
            "iteration: 657\n",
            "loss is: [[0.64852141]]\n",
            "iteration: 658\n",
            "loss is: [[0.6541342]]\n",
            "iteration: 659\n",
            "loss is: [[0.64962609]]\n",
            "iteration: 660\n",
            "loss is: [[0.64413773]]\n",
            "iteration: 661\n",
            "loss is: [[0.64707638]]\n",
            "iteration: 662\n",
            "loss is: [[0.67309507]]\n",
            "iteration: 663\n",
            "loss is: [[0.68937841]]\n",
            "iteration: 664\n",
            "loss is: [[0.67911229]]\n",
            "iteration: 665\n",
            "loss is: [[0.66997647]]\n",
            "iteration: 666\n",
            "loss is: [[0.69271278]]\n",
            "iteration: 667\n",
            "loss is: [[0.69747143]]\n",
            "iteration: 668\n",
            "loss is: [[0.65320702]]\n",
            "iteration: 669\n",
            "loss is: [[0.68896585]]\n",
            "iteration: 670\n",
            "loss is: [[0.71429962]]\n",
            "iteration: 671\n",
            "loss is: [[0.6916833]]\n",
            "iteration: 672\n",
            "loss is: [[0.68772877]]\n",
            "iteration: 673\n",
            "loss is: [[0.71032322]]\n",
            "iteration: 674\n",
            "loss is: [[0.69890921]]\n",
            "iteration: 675\n",
            "loss is: [[0.68062369]]\n",
            "iteration: 676\n",
            "loss is: [[0.67825556]]\n",
            "iteration: 677\n",
            "loss is: [[0.65328254]]\n",
            "iteration: 678\n",
            "loss is: [[0.66067909]]\n",
            "iteration: 679\n",
            "loss is: [[0.67194896]]\n",
            "iteration: 680\n",
            "loss is: [[0.65874804]]\n",
            "iteration: 681\n",
            "loss is: [[0.65721013]]\n",
            "iteration: 682\n",
            "loss is: [[0.68778327]]\n",
            "iteration: 683\n",
            "loss is: [[0.65970473]]\n",
            "iteration: 684\n",
            "loss is: [[0.66261075]]\n",
            "iteration: 685\n",
            "loss is: [[0.66799621]]\n",
            "iteration: 686\n",
            "loss is: [[0.68714567]]\n",
            "iteration: 687\n",
            "loss is: [[0.66640113]]\n",
            "iteration: 688\n",
            "loss is: [[0.69316066]]\n",
            "iteration: 689\n",
            "loss is: [[0.68895257]]\n",
            "iteration: 690\n",
            "loss is: [[0.7049196]]\n",
            "iteration: 691\n",
            "loss is: [[0.68087345]]\n",
            "iteration: 692\n",
            "loss is: [[0.66609128]]\n",
            "iteration: 693\n",
            "loss is: [[0.68040941]]\n",
            "iteration: 694\n",
            "loss is: [[0.68748786]]\n",
            "iteration: 695\n",
            "loss is: [[0.68054485]]\n",
            "iteration: 696\n",
            "loss is: [[0.70461987]]\n",
            "iteration: 697\n",
            "loss is: [[0.70112114]]\n",
            "iteration: 698\n",
            "loss is: [[0.66181987]]\n",
            "iteration: 699\n",
            "loss is: [[0.67421743]]\n",
            "iteration: 700\n",
            "loss is: [[0.68873178]]\n",
            "iteration: 701\n",
            "loss is: [[0.69309787]]\n",
            "iteration: 702\n",
            "loss is: [[0.65260084]]\n",
            "iteration: 703\n",
            "loss is: [[0.65447646]]\n",
            "iteration: 704\n",
            "loss is: [[0.71710541]]\n",
            "iteration: 705\n",
            "loss is: [[0.67830015]]\n",
            "iteration: 706\n",
            "loss is: [[0.69231116]]\n",
            "iteration: 707\n",
            "loss is: [[0.69019414]]\n",
            "iteration: 708\n",
            "loss is: [[0.64728255]]\n",
            "iteration: 709\n",
            "loss is: [[0.66840449]]\n",
            "iteration: 710\n",
            "loss is: [[0.66018417]]\n",
            "iteration: 711\n",
            "loss is: [[0.69373233]]\n",
            "iteration: 712\n",
            "loss is: [[0.66566567]]\n",
            "iteration: 713\n",
            "loss is: [[0.66149954]]\n",
            "iteration: 714\n",
            "loss is: [[0.67221323]]\n",
            "iteration: 715\n",
            "loss is: [[0.67360321]]\n",
            "iteration: 716\n",
            "loss is: [[0.66549911]]\n",
            "iteration: 717\n",
            "loss is: [[0.65881134]]\n",
            "iteration: 718\n",
            "loss is: [[0.69688588]]\n",
            "iteration: 719\n",
            "loss is: [[0.65679929]]\n",
            "iteration: 720\n",
            "loss is: [[0.65675508]]\n",
            "iteration: 721\n",
            "loss is: [[0.69050407]]\n",
            "iteration: 722\n",
            "loss is: [[0.70247585]]\n",
            "iteration: 723\n",
            "loss is: [[0.66927117]]\n",
            "iteration: 724\n",
            "loss is: [[0.67856346]]\n",
            "iteration: 725\n",
            "loss is: [[0.65346558]]\n",
            "iteration: 726\n",
            "loss is: [[0.65937704]]\n",
            "iteration: 727\n",
            "loss is: [[0.66919046]]\n",
            "iteration: 728\n",
            "loss is: [[0.65801482]]\n",
            "iteration: 729\n",
            "loss is: [[0.69733136]]\n",
            "iteration: 730\n",
            "loss is: [[0.67622746]]\n",
            "iteration: 731\n",
            "loss is: [[0.69709311]]\n",
            "iteration: 732\n",
            "loss is: [[0.67315351]]\n",
            "iteration: 733\n",
            "loss is: [[0.65528903]]\n",
            "iteration: 734\n",
            "loss is: [[0.70121939]]\n",
            "iteration: 735\n",
            "loss is: [[0.72017]]\n",
            "iteration: 736\n",
            "loss is: [[0.68332229]]\n",
            "iteration: 737\n",
            "loss is: [[0.68417881]]\n",
            "iteration: 738\n",
            "loss is: [[0.6529765]]\n",
            "iteration: 739\n",
            "loss is: [[0.65855406]]\n",
            "iteration: 740\n",
            "loss is: [[0.66556605]]\n",
            "iteration: 741\n",
            "loss is: [[0.68829797]]\n",
            "iteration: 742\n",
            "loss is: [[0.7017934]]\n",
            "iteration: 743\n",
            "loss is: [[0.7067086]]\n",
            "iteration: 744\n",
            "loss is: [[0.70377467]]\n",
            "iteration: 745\n",
            "loss is: [[0.66471175]]\n",
            "iteration: 746\n",
            "loss is: [[0.70240813]]\n",
            "iteration: 747\n",
            "loss is: [[0.70258474]]\n",
            "iteration: 748\n",
            "loss is: [[0.67585918]]\n",
            "iteration: 749\n",
            "loss is: [[0.70452275]]\n",
            "iteration: 750\n",
            "loss is: [[0.66452899]]\n",
            "iteration: 751\n",
            "loss is: [[0.67672804]]\n",
            "iteration: 752\n",
            "loss is: [[0.70368071]]\n",
            "iteration: 753\n",
            "loss is: [[0.64915468]]\n",
            "iteration: 754\n",
            "loss is: [[0.68681963]]\n",
            "iteration: 755\n",
            "loss is: [[0.65945898]]\n",
            "iteration: 756\n",
            "loss is: [[0.68981975]]\n",
            "iteration: 757\n",
            "loss is: [[0.68952034]]\n",
            "iteration: 758\n",
            "loss is: [[0.67927127]]\n",
            "iteration: 759\n",
            "loss is: [[0.69750651]]\n",
            "iteration: 760\n",
            "loss is: [[0.69577723]]\n",
            "iteration: 761\n",
            "loss is: [[0.68956357]]\n",
            "iteration: 762\n",
            "loss is: [[0.67039255]]\n",
            "iteration: 763\n",
            "loss is: [[0.68716037]]\n",
            "iteration: 764\n",
            "loss is: [[0.69156243]]\n",
            "iteration: 765\n",
            "loss is: [[0.65744423]]\n",
            "iteration: 766\n",
            "loss is: [[0.72198601]]\n",
            "iteration: 767\n",
            "loss is: [[0.71049256]]\n",
            "iteration: 768\n",
            "loss is: [[0.72746651]]\n",
            "iteration: 769\n",
            "loss is: [[0.73733455]]\n",
            "iteration: 770\n",
            "loss is: [[0.71825612]]\n",
            "iteration: 771\n",
            "loss is: [[0.69785781]]\n",
            "iteration: 772\n",
            "loss is: [[0.70508704]]\n",
            "iteration: 773\n",
            "loss is: [[0.70542677]]\n",
            "iteration: 774\n",
            "loss is: [[0.68767619]]\n",
            "iteration: 775\n",
            "loss is: [[0.64517517]]\n",
            "iteration: 776\n",
            "loss is: [[0.688715]]\n",
            "iteration: 777\n",
            "loss is: [[0.72942013]]\n",
            "iteration: 778\n",
            "loss is: [[0.67825183]]\n",
            "iteration: 779\n",
            "loss is: [[0.66779676]]\n",
            "iteration: 780\n",
            "loss is: [[0.68523006]]\n",
            "iteration: 781\n",
            "loss is: [[0.68629009]]\n",
            "iteration: 782\n",
            "loss is: [[0.68724487]]\n",
            "iteration: 783\n",
            "loss is: [[0.70390041]]\n",
            "iteration: 784\n",
            "loss is: [[0.67106303]]\n",
            "iteration: 785\n",
            "loss is: [[0.65744762]]\n",
            "iteration: 786\n",
            "loss is: [[0.66728815]]\n",
            "iteration: 787\n",
            "loss is: [[0.66025979]]\n",
            "iteration: 788\n",
            "loss is: [[0.67420426]]\n",
            "iteration: 789\n",
            "loss is: [[0.68010071]]\n",
            "iteration: 790\n",
            "loss is: [[0.65837233]]\n",
            "iteration: 791\n",
            "loss is: [[0.64088597]]\n",
            "iteration: 792\n",
            "loss is: [[0.67567628]]\n",
            "iteration: 793\n",
            "loss is: [[0.67952874]]\n",
            "iteration: 794\n",
            "loss is: [[0.66945264]]\n",
            "iteration: 795\n",
            "loss is: [[0.67271223]]\n",
            "iteration: 796\n",
            "loss is: [[0.68555889]]\n",
            "iteration: 797\n",
            "loss is: [[0.67330381]]\n",
            "iteration: 798\n",
            "loss is: [[0.66222658]]\n",
            "iteration: 799\n",
            "loss is: [[0.6970929]]\n",
            "iteration: 800\n",
            "loss is: [[0.69791169]]\n",
            "iteration: 801\n",
            "loss is: [[0.68993089]]\n",
            "iteration: 802\n",
            "loss is: [[0.67608269]]\n",
            "iteration: 803\n",
            "loss is: [[0.70410834]]\n",
            "iteration: 804\n",
            "loss is: [[0.682898]]\n",
            "iteration: 805\n",
            "loss is: [[0.70776543]]\n",
            "iteration: 806\n",
            "loss is: [[0.69073558]]\n",
            "iteration: 807\n",
            "loss is: [[0.64509761]]\n",
            "iteration: 808\n",
            "loss is: [[0.66777921]]\n",
            "iteration: 809\n",
            "loss is: [[0.67900713]]\n",
            "iteration: 810\n",
            "loss is: [[0.6554876]]\n",
            "iteration: 811\n",
            "loss is: [[0.65447505]]\n",
            "iteration: 812\n",
            "loss is: [[0.71515494]]\n",
            "iteration: 813\n",
            "loss is: [[0.6716427]]\n",
            "iteration: 814\n",
            "loss is: [[0.70014935]]\n",
            "iteration: 815\n",
            "loss is: [[0.68300499]]\n",
            "iteration: 816\n",
            "loss is: [[0.66097337]]\n",
            "iteration: 817\n",
            "loss is: [[0.65102864]]\n",
            "iteration: 818\n",
            "loss is: [[0.6581172]]\n",
            "iteration: 819\n",
            "loss is: [[0.65138546]]\n",
            "iteration: 820\n",
            "loss is: [[0.67214618]]\n",
            "iteration: 821\n",
            "loss is: [[0.63566512]]\n",
            "iteration: 822\n",
            "loss is: [[0.65919071]]\n",
            "iteration: 823\n",
            "loss is: [[0.71196508]]\n",
            "iteration: 824\n",
            "loss is: [[0.68188596]]\n",
            "iteration: 825\n",
            "loss is: [[0.67721625]]\n",
            "iteration: 826\n",
            "loss is: [[0.64914824]]\n",
            "iteration: 827\n",
            "loss is: [[0.6827745]]\n",
            "iteration: 828\n",
            "loss is: [[0.65641385]]\n",
            "iteration: 829\n",
            "loss is: [[0.69653826]]\n",
            "iteration: 830\n",
            "loss is: [[0.71203942]]\n",
            "iteration: 831\n",
            "loss is: [[0.66280893]]\n",
            "iteration: 832\n",
            "loss is: [[0.66812223]]\n",
            "iteration: 833\n",
            "loss is: [[0.69089828]]\n",
            "iteration: 834\n",
            "loss is: [[0.69515555]]\n",
            "iteration: 835\n",
            "loss is: [[0.71798636]]\n",
            "iteration: 836\n",
            "loss is: [[0.68563703]]\n",
            "iteration: 837\n",
            "loss is: [[0.67090424]]\n",
            "iteration: 838\n",
            "loss is: [[0.69522637]]\n",
            "iteration: 839\n",
            "loss is: [[0.65699178]]\n",
            "iteration: 840\n",
            "loss is: [[0.71245948]]\n",
            "iteration: 841\n",
            "loss is: [[0.67456335]]\n",
            "iteration: 842\n",
            "loss is: [[0.67094703]]\n",
            "iteration: 843\n",
            "loss is: [[0.67615781]]\n",
            "iteration: 844\n",
            "loss is: [[0.67892414]]\n",
            "iteration: 845\n",
            "loss is: [[0.67261065]]\n",
            "iteration: 846\n",
            "loss is: [[0.72809788]]\n",
            "iteration: 847\n",
            "loss is: [[0.71443129]]\n",
            "iteration: 848\n",
            "loss is: [[0.70009722]]\n",
            "iteration: 849\n",
            "loss is: [[0.70439259]]\n",
            "iteration: 850\n",
            "loss is: [[0.68694462]]\n",
            "iteration: 851\n",
            "loss is: [[0.72198314]]\n",
            "iteration: 852\n",
            "loss is: [[0.71675984]]\n",
            "iteration: 853\n",
            "loss is: [[0.68479831]]\n",
            "iteration: 854\n",
            "loss is: [[0.70908225]]\n",
            "iteration: 855\n",
            "loss is: [[0.68130022]]\n",
            "iteration: 856\n",
            "loss is: [[0.66851168]]\n",
            "iteration: 857\n",
            "loss is: [[0.70752253]]\n",
            "iteration: 858\n",
            "loss is: [[0.66083932]]\n",
            "iteration: 859\n",
            "loss is: [[0.67738445]]\n",
            "iteration: 860\n",
            "loss is: [[0.67055542]]\n",
            "iteration: 861\n",
            "loss is: [[0.68799856]]\n",
            "iteration: 862\n",
            "loss is: [[0.65812297]]\n",
            "iteration: 863\n",
            "loss is: [[0.67489795]]\n",
            "iteration: 864\n",
            "loss is: [[0.68578001]]\n",
            "iteration: 865\n",
            "loss is: [[0.70055973]]\n",
            "iteration: 866\n",
            "loss is: [[0.67876529]]\n",
            "iteration: 867\n",
            "loss is: [[0.6925433]]\n",
            "iteration: 868\n",
            "loss is: [[0.68616398]]\n",
            "iteration: 869\n",
            "loss is: [[0.67614302]]\n",
            "iteration: 870\n",
            "loss is: [[0.70262113]]\n",
            "iteration: 871\n",
            "loss is: [[0.67679946]]\n",
            "iteration: 872\n",
            "loss is: [[0.66929942]]\n",
            "iteration: 873\n",
            "loss is: [[0.66476869]]\n",
            "iteration: 874\n",
            "loss is: [[0.65212419]]\n",
            "iteration: 875\n",
            "loss is: [[0.65358046]]\n",
            "iteration: 876\n",
            "loss is: [[0.69164376]]\n",
            "iteration: 877\n",
            "loss is: [[0.6961551]]\n",
            "iteration: 878\n",
            "loss is: [[0.68442421]]\n",
            "iteration: 879\n",
            "loss is: [[0.66679919]]\n",
            "iteration: 880\n",
            "loss is: [[0.66863566]]\n",
            "iteration: 881\n",
            "loss is: [[0.73637908]]\n",
            "iteration: 882\n",
            "loss is: [[0.6645002]]\n",
            "iteration: 883\n",
            "loss is: [[0.68203802]]\n",
            "iteration: 884\n",
            "loss is: [[0.68226831]]\n",
            "iteration: 885\n",
            "loss is: [[0.67880174]]\n",
            "iteration: 886\n",
            "loss is: [[0.70218506]]\n",
            "iteration: 887\n",
            "loss is: [[0.6873983]]\n",
            "iteration: 888\n",
            "loss is: [[0.67371773]]\n",
            "iteration: 889\n",
            "loss is: [[0.66801748]]\n",
            "iteration: 890\n",
            "loss is: [[0.67519792]]\n",
            "iteration: 891\n",
            "loss is: [[0.68850521]]\n",
            "iteration: 892\n",
            "loss is: [[0.7055598]]\n",
            "iteration: 893\n",
            "loss is: [[0.68595538]]\n",
            "iteration: 894\n",
            "loss is: [[0.7064087]]\n",
            "iteration: 895\n",
            "loss is: [[0.68353826]]\n",
            "iteration: 896\n",
            "loss is: [[0.7070693]]\n",
            "iteration: 897\n",
            "loss is: [[0.69080422]]\n",
            "iteration: 898\n",
            "loss is: [[0.68185236]]\n",
            "iteration: 899\n",
            "loss is: [[0.66863023]]\n",
            "iteration: 900\n",
            "loss is: [[0.67129713]]\n",
            "iteration: 901\n",
            "loss is: [[0.7007415]]\n",
            "iteration: 902\n",
            "loss is: [[0.68077233]]\n",
            "iteration: 903\n",
            "loss is: [[0.72546053]]\n",
            "iteration: 904\n",
            "loss is: [[0.6685074]]\n",
            "iteration: 905\n",
            "loss is: [[0.68430076]]\n",
            "iteration: 906\n",
            "loss is: [[0.69057988]]\n",
            "iteration: 907\n",
            "loss is: [[0.64907652]]\n",
            "iteration: 908\n",
            "loss is: [[0.66037608]]\n",
            "iteration: 909\n",
            "loss is: [[0.68176754]]\n",
            "iteration: 910\n",
            "loss is: [[0.69457266]]\n",
            "iteration: 911\n",
            "loss is: [[0.72003]]\n",
            "iteration: 912\n",
            "loss is: [[0.67370256]]\n",
            "iteration: 913\n",
            "loss is: [[0.68839583]]\n",
            "iteration: 914\n",
            "loss is: [[0.69989606]]\n",
            "iteration: 915\n",
            "loss is: [[0.6917618]]\n",
            "iteration: 916\n",
            "loss is: [[0.66829754]]\n",
            "iteration: 917\n",
            "loss is: [[0.6655508]]\n",
            "iteration: 918\n",
            "loss is: [[0.63609992]]\n",
            "iteration: 919\n",
            "loss is: [[0.67037156]]\n",
            "iteration: 920\n",
            "loss is: [[0.66854793]]\n",
            "iteration: 921\n",
            "loss is: [[0.64355043]]\n",
            "iteration: 922\n",
            "loss is: [[0.68234157]]\n",
            "iteration: 923\n",
            "loss is: [[0.66347019]]\n",
            "iteration: 924\n",
            "loss is: [[0.69433636]]\n",
            "iteration: 925\n",
            "loss is: [[0.67885548]]\n",
            "iteration: 926\n",
            "loss is: [[0.68715984]]\n",
            "iteration: 927\n",
            "loss is: [[0.67843442]]\n",
            "iteration: 928\n",
            "loss is: [[0.65495298]]\n",
            "iteration: 929\n",
            "loss is: [[0.64345733]]\n",
            "iteration: 930\n",
            "loss is: [[0.66944333]]\n",
            "iteration: 931\n",
            "loss is: [[0.68486843]]\n",
            "iteration: 932\n",
            "loss is: [[0.68553133]]\n",
            "iteration: 933\n",
            "loss is: [[0.64790256]]\n",
            "iteration: 934\n",
            "loss is: [[0.69234469]]\n",
            "iteration: 935\n",
            "loss is: [[0.68656669]]\n",
            "iteration: 936\n",
            "loss is: [[0.67147753]]\n",
            "iteration: 937\n",
            "loss is: [[0.67827476]]\n",
            "iteration: 938\n",
            "loss is: [[0.70769149]]\n",
            "iteration: 939\n",
            "loss is: [[0.70341862]]\n",
            "iteration: 940\n",
            "loss is: [[0.67254714]]\n",
            "iteration: 941\n",
            "loss is: [[0.69293581]]\n",
            "iteration: 942\n",
            "loss is: [[0.68171065]]\n",
            "iteration: 943\n",
            "loss is: [[0.65711287]]\n",
            "iteration: 944\n",
            "loss is: [[0.69214118]]\n",
            "iteration: 945\n",
            "loss is: [[0.68369739]]\n",
            "iteration: 946\n",
            "loss is: [[0.66761696]]\n",
            "iteration: 947\n",
            "loss is: [[0.6862743]]\n",
            "iteration: 948\n",
            "loss is: [[0.70651119]]\n",
            "iteration: 949\n",
            "loss is: [[0.70657418]]\n",
            "iteration: 950\n",
            "loss is: [[0.6725624]]\n",
            "iteration: 951\n",
            "loss is: [[0.66907301]]\n",
            "iteration: 952\n",
            "loss is: [[0.68490161]]\n",
            "iteration: 953\n",
            "loss is: [[0.64797884]]\n",
            "iteration: 954\n",
            "loss is: [[0.66018891]]\n",
            "iteration: 955\n",
            "loss is: [[0.69235724]]\n",
            "iteration: 956\n",
            "loss is: [[0.6727421]]\n",
            "iteration: 957\n",
            "loss is: [[0.66845965]]\n",
            "iteration: 958\n",
            "loss is: [[0.69072783]]\n",
            "iteration: 959\n",
            "loss is: [[0.67189046]]\n",
            "iteration: 960\n",
            "loss is: [[0.68497132]]\n",
            "iteration: 961\n",
            "loss is: [[0.69849954]]\n",
            "iteration: 962\n",
            "loss is: [[0.66657721]]\n",
            "iteration: 963\n",
            "loss is: [[0.69451415]]\n",
            "iteration: 964\n",
            "loss is: [[0.68388592]]\n",
            "iteration: 965\n",
            "loss is: [[0.71865156]]\n",
            "iteration: 966\n",
            "loss is: [[0.66496426]]\n",
            "iteration: 967\n",
            "loss is: [[0.7252011]]\n",
            "iteration: 968\n",
            "loss is: [[0.70584652]]\n",
            "iteration: 969\n",
            "loss is: [[0.71840642]]\n",
            "iteration: 970\n",
            "loss is: [[0.6840876]]\n",
            "iteration: 971\n",
            "loss is: [[0.69066345]]\n",
            "iteration: 972\n",
            "loss is: [[0.70333836]]\n",
            "iteration: 973\n",
            "loss is: [[0.66268232]]\n",
            "iteration: 974\n",
            "loss is: [[0.66336909]]\n",
            "iteration: 975\n",
            "loss is: [[0.69841308]]\n",
            "iteration: 976\n",
            "loss is: [[0.68237601]]\n",
            "iteration: 977\n",
            "loss is: [[0.67932691]]\n",
            "iteration: 978\n",
            "loss is: [[0.66999664]]\n",
            "iteration: 979\n",
            "loss is: [[0.65882317]]\n",
            "iteration: 980\n",
            "loss is: [[0.69847429]]\n",
            "iteration: 981\n",
            "loss is: [[0.68755167]]\n",
            "iteration: 982\n",
            "loss is: [[0.69749851]]\n",
            "iteration: 983\n",
            "loss is: [[0.68904246]]\n",
            "iteration: 984\n",
            "loss is: [[0.6917853]]\n",
            "iteration: 985\n",
            "loss is: [[0.68772093]]\n",
            "iteration: 986\n",
            "loss is: [[0.699708]]\n",
            "iteration: 987\n",
            "loss is: [[0.65954317]]\n",
            "iteration: 988\n",
            "loss is: [[0.67727501]]\n",
            "iteration: 989\n",
            "loss is: [[0.65803636]]\n",
            "iteration: 990\n",
            "loss is: [[0.70683923]]\n",
            "iteration: 991\n",
            "loss is: [[0.67005467]]\n",
            "iteration: 992\n",
            "loss is: [[0.65137664]]\n",
            "iteration: 993\n",
            "loss is: [[0.67839448]]\n",
            "iteration: 994\n",
            "loss is: [[0.6711383]]\n",
            "iteration: 995\n",
            "loss is: [[0.66571774]]\n",
            "iteration: 996\n",
            "loss is: [[0.65178638]]\n",
            "iteration: 997\n",
            "loss is: [[0.68690645]]\n",
            "iteration: 998\n",
            "loss is: [[0.69320645]]\n",
            "iteration: 999\n",
            "loss is: [[0.67203995]]\n",
            "iteration: 1000\n",
            "loss is: [[0.69997631]]\n",
            "iteration: 1001\n",
            "loss is: [[0.69990233]]\n",
            "iteration: 1002\n",
            "loss is: [[0.65399251]]\n",
            "iteration: 1003\n",
            "loss is: [[0.68798887]]\n",
            "iteration: 1004\n",
            "loss is: [[0.68898805]]\n",
            "iteration: 1005\n",
            "loss is: [[0.69428868]]\n",
            "iteration: 1006\n",
            "loss is: [[0.70441174]]\n",
            "iteration: 1007\n",
            "loss is: [[0.68941718]]\n",
            "iteration: 1008\n",
            "loss is: [[0.67865387]]\n",
            "iteration: 1009\n",
            "loss is: [[0.65129847]]\n",
            "iteration: 1010\n",
            "loss is: [[0.68530118]]\n",
            "iteration: 1011\n",
            "loss is: [[0.68347571]]\n",
            "iteration: 1012\n",
            "loss is: [[0.71401485]]\n",
            "iteration: 1013\n",
            "loss is: [[0.73669325]]\n",
            "iteration: 1014\n",
            "loss is: [[0.67790686]]\n",
            "iteration: 1015\n",
            "loss is: [[0.72029881]]\n",
            "iteration: 1016\n",
            "loss is: [[0.65588655]]\n",
            "iteration: 1017\n",
            "loss is: [[0.71428846]]\n",
            "iteration: 1018\n",
            "loss is: [[0.66570789]]\n",
            "iteration: 1019\n",
            "loss is: [[0.66562073]]\n",
            "iteration: 1020\n",
            "loss is: [[0.67556449]]\n",
            "iteration: 1021\n",
            "loss is: [[0.65858571]]\n",
            "iteration: 1022\n",
            "loss is: [[0.64764205]]\n",
            "iteration: 1023\n",
            "loss is: [[0.72161331]]\n",
            "iteration: 1024\n",
            "loss is: [[0.67620709]]\n",
            "iteration: 1025\n",
            "loss is: [[0.65305073]]\n",
            "iteration: 1026\n",
            "loss is: [[0.68267431]]\n",
            "iteration: 1027\n",
            "loss is: [[0.68445951]]\n",
            "iteration: 1028\n",
            "loss is: [[0.73399732]]\n",
            "iteration: 1029\n",
            "loss is: [[0.70484729]]\n",
            "iteration: 1030\n",
            "loss is: [[0.69283353]]\n",
            "iteration: 1031\n",
            "loss is: [[0.66600574]]\n",
            "iteration: 1032\n",
            "loss is: [[0.66773072]]\n",
            "iteration: 1033\n",
            "loss is: [[0.66755028]]\n",
            "iteration: 1034\n",
            "loss is: [[0.67506543]]\n",
            "iteration: 1035\n",
            "loss is: [[0.67238017]]\n",
            "iteration: 1036\n",
            "loss is: [[0.70432441]]\n",
            "iteration: 1037\n",
            "loss is: [[0.66237714]]\n",
            "iteration: 1038\n",
            "loss is: [[0.68640615]]\n",
            "iteration: 1039\n",
            "loss is: [[0.70669134]]\n",
            "iteration: 1040\n",
            "loss is: [[0.70206107]]\n",
            "iteration: 1041\n",
            "loss is: [[0.70379822]]\n",
            "iteration: 1042\n",
            "loss is: [[0.70490965]]\n",
            "iteration: 1043\n",
            "loss is: [[0.72869177]]\n",
            "iteration: 1044\n",
            "loss is: [[0.6436469]]\n",
            "iteration: 1045\n",
            "loss is: [[0.69503976]]\n",
            "iteration: 1046\n",
            "loss is: [[0.71998212]]\n",
            "iteration: 1047\n",
            "loss is: [[0.70221825]]\n",
            "iteration: 1048\n",
            "loss is: [[0.67886181]]\n",
            "iteration: 1049\n",
            "loss is: [[0.66114527]]\n",
            "iteration: 1050\n",
            "loss is: [[0.68754115]]\n",
            "iteration: 1051\n",
            "loss is: [[0.68112738]]\n",
            "iteration: 1052\n",
            "loss is: [[0.65901512]]\n",
            "iteration: 1053\n",
            "loss is: [[0.67720549]]\n",
            "iteration: 1054\n",
            "loss is: [[0.65801762]]\n",
            "iteration: 1055\n",
            "loss is: [[0.67421076]]\n",
            "iteration: 1056\n",
            "loss is: [[0.6853337]]\n",
            "iteration: 1057\n",
            "loss is: [[0.652679]]\n",
            "iteration: 1058\n",
            "loss is: [[0.70639743]]\n",
            "iteration: 1059\n",
            "loss is: [[0.68788264]]\n",
            "iteration: 1060\n",
            "loss is: [[0.69427259]]\n",
            "iteration: 1061\n",
            "loss is: [[0.69050066]]\n",
            "iteration: 1062\n",
            "loss is: [[0.68585812]]\n",
            "iteration: 1063\n",
            "loss is: [[0.66810822]]\n",
            "iteration: 1064\n",
            "loss is: [[0.6419288]]\n",
            "iteration: 1065\n",
            "loss is: [[0.70542577]]\n",
            "iteration: 1066\n",
            "loss is: [[0.6875314]]\n",
            "iteration: 1067\n",
            "loss is: [[0.66279495]]\n",
            "iteration: 1068\n",
            "loss is: [[0.65359517]]\n",
            "iteration: 1069\n",
            "loss is: [[0.69428897]]\n",
            "iteration: 1070\n",
            "loss is: [[0.68385708]]\n",
            "iteration: 1071\n",
            "loss is: [[0.67589216]]\n",
            "iteration: 1072\n",
            "loss is: [[0.66573943]]\n",
            "iteration: 1073\n",
            "loss is: [[0.71935476]]\n",
            "iteration: 1074\n",
            "loss is: [[0.7090191]]\n",
            "iteration: 1075\n",
            "loss is: [[0.70688931]]\n",
            "iteration: 1076\n",
            "loss is: [[0.64879396]]\n",
            "iteration: 1077\n",
            "loss is: [[0.67585634]]\n",
            "iteration: 1078\n",
            "loss is: [[0.68599568]]\n",
            "iteration: 1079\n",
            "loss is: [[0.69756016]]\n",
            "iteration: 1080\n",
            "loss is: [[0.67328426]]\n",
            "iteration: 1081\n",
            "loss is: [[0.67415572]]\n",
            "iteration: 1082\n",
            "loss is: [[0.69522774]]\n",
            "iteration: 1083\n",
            "loss is: [[0.67365273]]\n",
            "iteration: 1084\n",
            "loss is: [[0.68331849]]\n",
            "iteration: 1085\n",
            "loss is: [[0.67197248]]\n",
            "iteration: 1086\n",
            "loss is: [[0.70985536]]\n",
            "iteration: 1087\n",
            "loss is: [[0.70869628]]\n",
            "iteration: 1088\n",
            "loss is: [[0.66173342]]\n",
            "iteration: 1089\n",
            "loss is: [[0.67191827]]\n",
            "iteration: 1090\n",
            "loss is: [[0.69815129]]\n",
            "iteration: 1091\n",
            "loss is: [[0.71407132]]\n",
            "iteration: 1092\n",
            "loss is: [[0.69844422]]\n",
            "iteration: 1093\n",
            "loss is: [[0.67437696]]\n",
            "iteration: 1094\n",
            "loss is: [[0.71779811]]\n",
            "iteration: 1095\n",
            "loss is: [[0.67352593]]\n",
            "iteration: 1096\n",
            "loss is: [[0.67921549]]\n",
            "iteration: 1097\n",
            "loss is: [[0.6939308]]\n",
            "iteration: 1098\n",
            "loss is: [[0.6824197]]\n",
            "iteration: 1099\n",
            "loss is: [[0.66994842]]\n",
            "iteration: 1100\n",
            "loss is: [[0.69686523]]\n",
            "iteration: 1101\n",
            "loss is: [[0.67503455]]\n",
            "iteration: 1102\n",
            "loss is: [[0.65841117]]\n",
            "iteration: 1103\n",
            "loss is: [[0.67700806]]\n",
            "iteration: 1104\n",
            "loss is: [[0.66525306]]\n",
            "iteration: 1105\n",
            "loss is: [[0.69016705]]\n",
            "iteration: 1106\n",
            "loss is: [[0.70356267]]\n",
            "iteration: 1107\n",
            "loss is: [[0.64932911]]\n",
            "iteration: 1108\n",
            "loss is: [[0.65576246]]\n",
            "iteration: 1109\n",
            "loss is: [[0.67440376]]\n",
            "iteration: 1110\n",
            "loss is: [[0.69304367]]\n",
            "iteration: 1111\n",
            "loss is: [[0.70962207]]\n",
            "iteration: 1112\n",
            "loss is: [[0.64243532]]\n",
            "iteration: 1113\n",
            "loss is: [[0.69284947]]\n",
            "iteration: 1114\n",
            "loss is: [[0.6802474]]\n",
            "iteration: 1115\n",
            "loss is: [[0.6712331]]\n",
            "iteration: 1116\n",
            "loss is: [[0.68645186]]\n",
            "iteration: 1117\n",
            "loss is: [[0.67180782]]\n",
            "iteration: 1118\n",
            "loss is: [[0.67057951]]\n",
            "iteration: 1119\n",
            "loss is: [[0.68047074]]\n",
            "iteration: 1120\n",
            "loss is: [[0.66974789]]\n",
            "iteration: 1121\n",
            "loss is: [[0.68973127]]\n",
            "iteration: 1122\n",
            "loss is: [[0.68593517]]\n",
            "iteration: 1123\n",
            "loss is: [[0.67464333]]\n",
            "iteration: 1124\n",
            "loss is: [[0.64975453]]\n",
            "iteration: 1125\n",
            "loss is: [[0.63962164]]\n",
            "iteration: 1126\n",
            "loss is: [[0.65956488]]\n",
            "iteration: 1127\n",
            "loss is: [[0.68836115]]\n",
            "iteration: 1128\n",
            "loss is: [[0.68540964]]\n",
            "iteration: 1129\n",
            "loss is: [[0.69510603]]\n",
            "iteration: 1130\n",
            "loss is: [[0.70059225]]\n",
            "iteration: 1131\n",
            "loss is: [[0.67929279]]\n",
            "iteration: 1132\n",
            "loss is: [[0.67987317]]\n",
            "iteration: 1133\n",
            "loss is: [[0.68088314]]\n",
            "iteration: 1134\n",
            "loss is: [[0.67694405]]\n",
            "iteration: 1135\n",
            "loss is: [[0.72290844]]\n",
            "iteration: 1136\n",
            "loss is: [[0.68690068]]\n",
            "iteration: 1137\n",
            "loss is: [[0.70889829]]\n",
            "iteration: 1138\n",
            "loss is: [[0.67911439]]\n",
            "iteration: 1139\n",
            "loss is: [[0.70381041]]\n",
            "iteration: 1140\n",
            "loss is: [[0.67361649]]\n",
            "iteration: 1141\n",
            "loss is: [[0.64864507]]\n",
            "iteration: 1142\n",
            "loss is: [[0.67451401]]\n",
            "iteration: 1143\n",
            "loss is: [[0.67599254]]\n",
            "iteration: 1144\n",
            "loss is: [[0.67866938]]\n",
            "iteration: 1145\n",
            "loss is: [[0.68084962]]\n",
            "iteration: 1146\n",
            "loss is: [[0.68354613]]\n",
            "iteration: 1147\n",
            "loss is: [[0.67763109]]\n",
            "iteration: 1148\n",
            "loss is: [[0.68442285]]\n",
            "iteration: 1149\n",
            "loss is: [[0.68185436]]\n",
            "iteration: 1150\n",
            "loss is: [[0.6869898]]\n",
            "iteration: 1151\n",
            "loss is: [[0.66390505]]\n",
            "iteration: 1152\n",
            "loss is: [[0.71737022]]\n",
            "iteration: 1153\n",
            "loss is: [[0.7108033]]\n",
            "iteration: 1154\n",
            "loss is: [[0.70415386]]\n",
            "iteration: 1155\n",
            "loss is: [[0.71936587]]\n",
            "iteration: 1156\n",
            "loss is: [[0.67278662]]\n",
            "iteration: 1157\n",
            "loss is: [[0.72756353]]\n",
            "iteration: 1158\n",
            "loss is: [[0.68650943]]\n",
            "iteration: 1159\n",
            "loss is: [[0.68099959]]\n",
            "iteration: 1160\n",
            "loss is: [[0.67750248]]\n",
            "iteration: 1161\n",
            "loss is: [[0.6632213]]\n",
            "iteration: 1162\n",
            "loss is: [[0.67988745]]\n",
            "iteration: 1163\n",
            "loss is: [[0.65079189]]\n",
            "iteration: 1164\n",
            "loss is: [[0.65788106]]\n",
            "iteration: 1165\n",
            "loss is: [[0.69707371]]\n",
            "iteration: 1166\n",
            "loss is: [[0.68999287]]\n",
            "iteration: 1167\n",
            "loss is: [[0.70235188]]\n",
            "iteration: 1168\n",
            "loss is: [[0.68055369]]\n",
            "iteration: 1169\n",
            "loss is: [[0.71784497]]\n",
            "iteration: 1170\n",
            "loss is: [[0.6734304]]\n",
            "iteration: 1171\n",
            "loss is: [[0.66848367]]\n",
            "iteration: 1172\n",
            "loss is: [[0.67610795]]\n",
            "iteration: 1173\n",
            "loss is: [[0.68508626]]\n",
            "iteration: 1174\n",
            "loss is: [[0.66286465]]\n",
            "iteration: 1175\n",
            "loss is: [[0.63667805]]\n",
            "iteration: 1176\n",
            "loss is: [[0.67799893]]\n",
            "iteration: 1177\n",
            "loss is: [[0.66783351]]\n",
            "iteration: 1178\n",
            "loss is: [[0.71238161]]\n",
            "iteration: 1179\n",
            "loss is: [[0.68617634]]\n",
            "iteration: 1180\n",
            "loss is: [[0.69681067]]\n",
            "iteration: 1181\n",
            "loss is: [[0.67476215]]\n",
            "iteration: 1182\n",
            "loss is: [[0.69891505]]\n",
            "iteration: 1183\n",
            "loss is: [[0.69412133]]\n",
            "iteration: 1184\n",
            "loss is: [[0.70493605]]\n",
            "iteration: 1185\n",
            "loss is: [[0.69247489]]\n",
            "iteration: 1186\n",
            "loss is: [[0.6428995]]\n",
            "iteration: 1187\n",
            "loss is: [[0.65549844]]\n",
            "iteration: 1188\n",
            "loss is: [[0.68662354]]\n",
            "iteration: 1189\n",
            "loss is: [[0.70585231]]\n",
            "iteration: 1190\n",
            "loss is: [[0.67463726]]\n",
            "iteration: 1191\n",
            "loss is: [[0.66530743]]\n",
            "iteration: 1192\n",
            "loss is: [[0.68657486]]\n",
            "iteration: 1193\n",
            "loss is: [[0.6945792]]\n",
            "iteration: 1194\n",
            "loss is: [[0.69075556]]\n",
            "iteration: 1195\n",
            "loss is: [[0.66185362]]\n",
            "iteration: 1196\n",
            "loss is: [[0.62391526]]\n",
            "iteration: 1197\n",
            "loss is: [[0.66108269]]\n",
            "iteration: 1198\n",
            "loss is: [[0.64563123]]\n",
            "iteration: 1199\n",
            "loss is: [[0.73982754]]\n",
            "iteration: 1200\n",
            "loss is: [[0.67243719]]\n",
            "iteration: 1201\n",
            "loss is: [[0.68660405]]\n",
            "iteration: 1202\n",
            "loss is: [[0.68521459]]\n",
            "iteration: 1203\n",
            "loss is: [[0.69148109]]\n",
            "iteration: 1204\n",
            "loss is: [[0.67255049]]\n",
            "iteration: 1205\n",
            "loss is: [[0.68391736]]\n",
            "iteration: 1206\n",
            "loss is: [[0.68279713]]\n",
            "iteration: 1207\n",
            "loss is: [[0.71393121]]\n",
            "iteration: 1208\n",
            "loss is: [[0.67346192]]\n",
            "iteration: 1209\n",
            "loss is: [[0.71027303]]\n",
            "iteration: 1210\n",
            "loss is: [[0.65076909]]\n",
            "iteration: 1211\n",
            "loss is: [[0.70096745]]\n",
            "iteration: 1212\n",
            "loss is: [[0.69093909]]\n",
            "iteration: 1213\n",
            "loss is: [[0.68687513]]\n",
            "iteration: 1214\n",
            "loss is: [[0.70932653]]\n",
            "iteration: 1215\n",
            "loss is: [[0.70025929]]\n",
            "iteration: 1216\n",
            "loss is: [[0.68505513]]\n",
            "iteration: 1217\n",
            "loss is: [[0.69706238]]\n",
            "iteration: 1218\n",
            "loss is: [[0.71656284]]\n",
            "iteration: 1219\n",
            "loss is: [[0.65746628]]\n",
            "iteration: 1220\n",
            "loss is: [[0.64718535]]\n",
            "iteration: 1221\n",
            "loss is: [[0.69664912]]\n",
            "iteration: 1222\n",
            "loss is: [[0.66558205]]\n",
            "iteration: 1223\n",
            "loss is: [[0.66194493]]\n",
            "iteration: 1224\n",
            "loss is: [[0.70480899]]\n",
            "iteration: 1225\n",
            "loss is: [[0.69343193]]\n",
            "iteration: 1226\n",
            "loss is: [[0.69085363]]\n",
            "iteration: 1227\n",
            "loss is: [[0.69078638]]\n",
            "iteration: 1228\n",
            "loss is: [[0.68165612]]\n",
            "iteration: 1229\n",
            "loss is: [[0.68678833]]\n",
            "iteration: 1230\n",
            "loss is: [[0.66207306]]\n",
            "iteration: 1231\n",
            "loss is: [[0.70225697]]\n",
            "iteration: 1232\n",
            "loss is: [[0.6587229]]\n",
            "iteration: 1233\n",
            "loss is: [[0.7065442]]\n",
            "iteration: 1234\n",
            "loss is: [[0.7161132]]\n",
            "iteration: 1235\n",
            "loss is: [[0.65050774]]\n",
            "iteration: 1236\n",
            "loss is: [[0.68244944]]\n",
            "iteration: 1237\n",
            "loss is: [[0.68607101]]\n",
            "iteration: 1238\n",
            "loss is: [[0.66665382]]\n",
            "iteration: 1239\n",
            "loss is: [[0.67415774]]\n",
            "iteration: 1240\n",
            "loss is: [[0.65595673]]\n",
            "iteration: 1241\n",
            "loss is: [[0.71988989]]\n",
            "iteration: 1242\n",
            "loss is: [[0.73588016]]\n",
            "iteration: 1243\n",
            "loss is: [[0.68669889]]\n",
            "iteration: 1244\n",
            "loss is: [[0.67673622]]\n",
            "iteration: 1245\n",
            "loss is: [[0.70390801]]\n",
            "iteration: 1246\n",
            "loss is: [[0.64772362]]\n",
            "iteration: 1247\n",
            "loss is: [[0.69656262]]\n",
            "iteration: 1248\n",
            "loss is: [[0.66650907]]\n",
            "iteration: 1249\n",
            "loss is: [[0.64579233]]\n",
            "iteration: 1250\n",
            "loss is: [[0.64836226]]\n",
            "iteration: 1251\n",
            "loss is: [[0.68012523]]\n",
            "iteration: 1252\n",
            "loss is: [[0.68047431]]\n",
            "iteration: 1253\n",
            "loss is: [[0.65255456]]\n",
            "iteration: 1254\n",
            "loss is: [[0.71084955]]\n",
            "iteration: 1255\n",
            "loss is: [[0.7205293]]\n",
            "iteration: 1256\n",
            "loss is: [[0.66602582]]\n",
            "iteration: 1257\n",
            "loss is: [[0.69529359]]\n",
            "iteration: 1258\n",
            "loss is: [[0.68581726]]\n",
            "iteration: 1259\n",
            "loss is: [[0.6633565]]\n",
            "iteration: 1260\n",
            "loss is: [[0.69068635]]\n",
            "iteration: 1261\n",
            "loss is: [[0.69010278]]\n",
            "iteration: 1262\n",
            "loss is: [[0.6899777]]\n",
            "iteration: 1263\n",
            "loss is: [[0.6715433]]\n",
            "iteration: 1264\n",
            "loss is: [[0.69816278]]\n",
            "iteration: 1265\n",
            "loss is: [[0.65326645]]\n",
            "iteration: 1266\n",
            "loss is: [[0.66443085]]\n",
            "iteration: 1267\n",
            "loss is: [[0.68167983]]\n",
            "iteration: 1268\n",
            "loss is: [[0.68206318]]\n",
            "iteration: 1269\n",
            "loss is: [[0.67992192]]\n",
            "iteration: 1270\n",
            "loss is: [[0.67033793]]\n",
            "iteration: 1271\n",
            "loss is: [[0.7152434]]\n",
            "iteration: 1272\n",
            "loss is: [[0.68554208]]\n",
            "iteration: 1273\n",
            "loss is: [[0.71414628]]\n",
            "iteration: 1274\n",
            "loss is: [[0.67737014]]\n",
            "iteration: 1275\n",
            "loss is: [[0.69488286]]\n",
            "iteration: 1276\n",
            "loss is: [[0.681347]]\n",
            "iteration: 1277\n",
            "loss is: [[0.67827932]]\n",
            "iteration: 1278\n",
            "loss is: [[0.66286172]]\n",
            "iteration: 1279\n",
            "loss is: [[0.68259762]]\n",
            "iteration: 1280\n",
            "loss is: [[0.65860465]]\n",
            "iteration: 1281\n",
            "loss is: [[0.70308925]]\n",
            "iteration: 1282\n",
            "loss is: [[0.68207566]]\n",
            "iteration: 1283\n",
            "loss is: [[0.69400453]]\n",
            "iteration: 1284\n",
            "loss is: [[0.68745205]]\n",
            "iteration: 1285\n",
            "loss is: [[0.67991601]]\n",
            "iteration: 1286\n",
            "loss is: [[0.66505279]]\n",
            "iteration: 1287\n",
            "loss is: [[0.70300654]]\n",
            "iteration: 1288\n",
            "loss is: [[0.66519076]]\n",
            "iteration: 1289\n",
            "loss is: [[0.70605026]]\n",
            "iteration: 1290\n",
            "loss is: [[0.69348493]]\n",
            "iteration: 1291\n",
            "loss is: [[0.67985948]]\n",
            "iteration: 1292\n",
            "loss is: [[0.66767099]]\n",
            "iteration: 1293\n",
            "loss is: [[0.66009502]]\n",
            "iteration: 1294\n",
            "loss is: [[0.67791353]]\n",
            "iteration: 1295\n",
            "loss is: [[0.68667255]]\n",
            "iteration: 1296\n",
            "loss is: [[0.68085846]]\n",
            "iteration: 1297\n",
            "loss is: [[0.67048926]]\n",
            "iteration: 1298\n",
            "loss is: [[0.70222656]]\n",
            "iteration: 1299\n",
            "loss is: [[0.68454192]]\n",
            "iteration: 1300\n",
            "loss is: [[0.69797438]]\n",
            "iteration: 1301\n",
            "loss is: [[0.68666522]]\n",
            "iteration: 1302\n",
            "loss is: [[0.705183]]\n",
            "iteration: 1303\n",
            "loss is: [[0.73990492]]\n",
            "iteration: 1304\n",
            "loss is: [[0.67448732]]\n",
            "iteration: 1305\n",
            "loss is: [[0.67461798]]\n",
            "iteration: 1306\n",
            "loss is: [[0.66096797]]\n",
            "iteration: 1307\n",
            "loss is: [[0.67969577]]\n",
            "iteration: 1308\n",
            "loss is: [[0.67975682]]\n",
            "iteration: 1309\n",
            "loss is: [[0.68428504]]\n",
            "iteration: 1310\n",
            "loss is: [[0.70690313]]\n",
            "iteration: 1311\n",
            "loss is: [[0.67443433]]\n",
            "iteration: 1312\n",
            "loss is: [[0.6643496]]\n",
            "iteration: 1313\n",
            "loss is: [[0.68877089]]\n",
            "iteration: 1314\n",
            "loss is: [[0.68950541]]\n",
            "iteration: 1315\n",
            "loss is: [[0.65623486]]\n",
            "iteration: 1316\n",
            "loss is: [[0.66145556]]\n",
            "iteration: 1317\n",
            "loss is: [[0.65672591]]\n",
            "iteration: 1318\n",
            "loss is: [[0.69772343]]\n",
            "iteration: 1319\n",
            "loss is: [[0.6531695]]\n",
            "iteration: 1320\n",
            "loss is: [[0.66348752]]\n",
            "iteration: 1321\n",
            "loss is: [[0.68419082]]\n",
            "iteration: 1322\n",
            "loss is: [[0.71534244]]\n",
            "iteration: 1323\n",
            "loss is: [[0.656671]]\n",
            "iteration: 1324\n",
            "loss is: [[0.62538607]]\n",
            "iteration: 1325\n",
            "loss is: [[0.6786647]]\n",
            "iteration: 1326\n",
            "loss is: [[0.68493846]]\n",
            "iteration: 1327\n",
            "loss is: [[0.64816623]]\n",
            "iteration: 1328\n",
            "loss is: [[0.66724456]]\n",
            "iteration: 1329\n",
            "loss is: [[0.68261658]]\n",
            "iteration: 1330\n",
            "loss is: [[0.68897774]]\n",
            "iteration: 1331\n",
            "loss is: [[0.67266002]]\n",
            "iteration: 1332\n",
            "loss is: [[0.69136875]]\n",
            "iteration: 1333\n",
            "loss is: [[0.71114226]]\n",
            "iteration: 1334\n",
            "loss is: [[0.67868666]]\n",
            "iteration: 1335\n",
            "loss is: [[0.7013377]]\n",
            "iteration: 1336\n",
            "loss is: [[0.68651146]]\n",
            "iteration: 1337\n",
            "loss is: [[0.65296711]]\n",
            "iteration: 1338\n",
            "loss is: [[0.71247522]]\n",
            "iteration: 1339\n",
            "loss is: [[0.67668604]]\n",
            "iteration: 1340\n",
            "loss is: [[0.66876841]]\n",
            "iteration: 1341\n",
            "loss is: [[0.6744351]]\n",
            "iteration: 1342\n",
            "loss is: [[0.66383307]]\n",
            "iteration: 1343\n",
            "loss is: [[0.70619326]]\n",
            "iteration: 1344\n",
            "loss is: [[0.66517512]]\n",
            "iteration: 1345\n",
            "loss is: [[0.70847678]]\n",
            "iteration: 1346\n",
            "loss is: [[0.63231599]]\n",
            "iteration: 1347\n",
            "loss is: [[0.65343375]]\n",
            "iteration: 1348\n",
            "loss is: [[0.66727126]]\n",
            "iteration: 1349\n",
            "loss is: [[0.66816516]]\n",
            "iteration: 1350\n",
            "loss is: [[0.68042744]]\n",
            "iteration: 1351\n",
            "loss is: [[0.67144346]]\n",
            "iteration: 1352\n",
            "loss is: [[0.71140387]]\n",
            "iteration: 1353\n",
            "loss is: [[0.68359042]]\n",
            "iteration: 1354\n",
            "loss is: [[0.66503373]]\n",
            "iteration: 1355\n",
            "loss is: [[0.69813439]]\n",
            "iteration: 1356\n",
            "loss is: [[0.68758261]]\n",
            "iteration: 1357\n",
            "loss is: [[0.68055522]]\n",
            "iteration: 1358\n",
            "loss is: [[0.69563792]]\n",
            "iteration: 1359\n",
            "loss is: [[0.684952]]\n",
            "iteration: 1360\n",
            "loss is: [[0.705749]]\n",
            "iteration: 1361\n",
            "loss is: [[0.66408042]]\n",
            "iteration: 1362\n",
            "loss is: [[0.69690659]]\n",
            "iteration: 1363\n",
            "loss is: [[0.71092461]]\n",
            "iteration: 1364\n",
            "loss is: [[0.65267193]]\n",
            "iteration: 1365\n",
            "loss is: [[0.66928687]]\n",
            "iteration: 1366\n",
            "loss is: [[0.69478583]]\n",
            "iteration: 1367\n",
            "loss is: [[0.70024409]]\n",
            "iteration: 1368\n",
            "loss is: [[0.67690992]]\n",
            "iteration: 1369\n",
            "loss is: [[0.71255794]]\n",
            "iteration: 1370\n",
            "loss is: [[0.67143191]]\n",
            "iteration: 1371\n",
            "loss is: [[0.6682495]]\n",
            "iteration: 1372\n",
            "loss is: [[0.6478523]]\n",
            "iteration: 1373\n",
            "loss is: [[0.65398363]]\n",
            "iteration: 1374\n",
            "loss is: [[0.68759437]]\n",
            "iteration: 1375\n",
            "loss is: [[0.66271318]]\n",
            "iteration: 1376\n",
            "loss is: [[0.67918792]]\n",
            "iteration: 1377\n",
            "loss is: [[0.66419638]]\n",
            "iteration: 1378\n",
            "loss is: [[0.70126951]]\n",
            "iteration: 1379\n",
            "loss is: [[0.6771818]]\n",
            "iteration: 1380\n",
            "loss is: [[0.6605766]]\n",
            "iteration: 1381\n",
            "loss is: [[0.68167899]]\n",
            "iteration: 1382\n",
            "loss is: [[0.67863444]]\n",
            "iteration: 1383\n",
            "loss is: [[0.66504172]]\n",
            "iteration: 1384\n",
            "loss is: [[0.65215839]]\n",
            "iteration: 1385\n",
            "loss is: [[0.70270109]]\n",
            "iteration: 1386\n",
            "loss is: [[0.71231313]]\n",
            "iteration: 1387\n",
            "loss is: [[0.68772415]]\n",
            "iteration: 1388\n",
            "loss is: [[0.73433028]]\n",
            "iteration: 1389\n",
            "loss is: [[0.67937176]]\n",
            "iteration: 1390\n",
            "loss is: [[0.69479153]]\n",
            "iteration: 1391\n",
            "loss is: [[0.67936143]]\n",
            "iteration: 1392\n",
            "loss is: [[0.69210608]]\n",
            "iteration: 1393\n",
            "loss is: [[0.70459436]]\n",
            "iteration: 1394\n",
            "loss is: [[0.67759967]]\n",
            "iteration: 1395\n",
            "loss is: [[0.67616825]]\n",
            "iteration: 1396\n",
            "loss is: [[0.7130179]]\n",
            "iteration: 1397\n",
            "loss is: [[0.7157934]]\n",
            "iteration: 1398\n",
            "loss is: [[0.75471643]]\n",
            "iteration: 1399\n",
            "loss is: [[0.71149977]]\n",
            "iteration: 1400\n",
            "loss is: [[0.68134588]]\n",
            "iteration: 1401\n",
            "loss is: [[0.67893822]]\n",
            "iteration: 1402\n",
            "loss is: [[0.67121032]]\n",
            "iteration: 1403\n",
            "loss is: [[0.69300491]]\n",
            "iteration: 1404\n",
            "loss is: [[0.65693277]]\n",
            "iteration: 1405\n",
            "loss is: [[0.68205006]]\n",
            "iteration: 1406\n",
            "loss is: [[0.63487835]]\n",
            "iteration: 1407\n",
            "loss is: [[0.66359084]]\n",
            "iteration: 1408\n",
            "loss is: [[0.70436571]]\n",
            "iteration: 1409\n",
            "loss is: [[0.69318743]]\n",
            "iteration: 1410\n",
            "loss is: [[0.67806386]]\n",
            "iteration: 1411\n",
            "loss is: [[0.70338237]]\n",
            "iteration: 1412\n",
            "loss is: [[0.68208814]]\n",
            "iteration: 1413\n",
            "loss is: [[0.67242698]]\n",
            "iteration: 1414\n",
            "loss is: [[0.65763668]]\n",
            "iteration: 1415\n",
            "loss is: [[0.69396356]]\n",
            "iteration: 1416\n",
            "loss is: [[0.62681087]]\n",
            "iteration: 1417\n",
            "loss is: [[0.69243633]]\n",
            "iteration: 1418\n",
            "loss is: [[0.65472532]]\n",
            "iteration: 1419\n",
            "loss is: [[0.67585128]]\n",
            "iteration: 1420\n",
            "loss is: [[0.70828579]]\n",
            "iteration: 1421\n",
            "loss is: [[0.69749472]]\n",
            "iteration: 1422\n",
            "loss is: [[0.69277645]]\n",
            "iteration: 1423\n",
            "loss is: [[0.68508534]]\n",
            "iteration: 1424\n",
            "loss is: [[0.69913606]]\n",
            "iteration: 1425\n",
            "loss is: [[0.68834371]]\n",
            "iteration: 1426\n",
            "loss is: [[0.69414089]]\n",
            "iteration: 1427\n",
            "loss is: [[0.67955173]]\n",
            "iteration: 1428\n",
            "loss is: [[0.66153525]]\n",
            "iteration: 1429\n",
            "loss is: [[0.69313536]]\n",
            "iteration: 1430\n",
            "loss is: [[0.67246337]]\n",
            "iteration: 1431\n",
            "loss is: [[0.67028479]]\n",
            "iteration: 1432\n",
            "loss is: [[0.68024735]]\n",
            "iteration: 1433\n",
            "loss is: [[0.68110046]]\n",
            "iteration: 1434\n",
            "loss is: [[0.69944936]]\n",
            "iteration: 1435\n",
            "loss is: [[0.68661245]]\n",
            "iteration: 1436\n",
            "loss is: [[0.69282295]]\n",
            "iteration: 1437\n",
            "loss is: [[0.68329674]]\n",
            "iteration: 1438\n",
            "loss is: [[0.64620483]]\n",
            "iteration: 1439\n",
            "loss is: [[0.64794678]]\n",
            "iteration: 1440\n",
            "loss is: [[0.69692839]]\n",
            "iteration: 1441\n",
            "loss is: [[0.67489119]]\n",
            "iteration: 1442\n",
            "loss is: [[0.69575357]]\n",
            "iteration: 1443\n",
            "loss is: [[0.70907371]]\n",
            "iteration: 1444\n",
            "loss is: [[0.72433176]]\n",
            "iteration: 1445\n",
            "loss is: [[0.69101106]]\n",
            "iteration: 1446\n",
            "loss is: [[0.70420586]]\n",
            "iteration: 1447\n",
            "loss is: [[0.68863853]]\n",
            "iteration: 1448\n",
            "loss is: [[0.67851085]]\n",
            "iteration: 1449\n",
            "loss is: [[0.64960028]]\n",
            "iteration: 1450\n",
            "loss is: [[0.6810462]]\n",
            "iteration: 1451\n",
            "loss is: [[0.69274228]]\n",
            "iteration: 1452\n",
            "loss is: [[0.70664913]]\n",
            "iteration: 1453\n",
            "loss is: [[0.69070401]]\n",
            "iteration: 1454\n",
            "loss is: [[0.69848439]]\n",
            "iteration: 1455\n",
            "loss is: [[0.71058328]]\n",
            "iteration: 1456\n",
            "loss is: [[0.73777931]]\n",
            "iteration: 1457\n",
            "loss is: [[0.71393909]]\n",
            "iteration: 1458\n",
            "loss is: [[0.67788854]]\n",
            "iteration: 1459\n",
            "loss is: [[0.67841495]]\n",
            "iteration: 1460\n",
            "loss is: [[0.67208028]]\n",
            "iteration: 1461\n",
            "loss is: [[0.67709725]]\n",
            "iteration: 1462\n",
            "loss is: [[0.67208397]]\n",
            "iteration: 1463\n",
            "loss is: [[0.72790668]]\n",
            "iteration: 1464\n",
            "loss is: [[0.68114074]]\n",
            "iteration: 1465\n",
            "loss is: [[0.71178657]]\n",
            "iteration: 1466\n",
            "loss is: [[0.71796349]]\n",
            "iteration: 1467\n",
            "loss is: [[0.68160259]]\n",
            "iteration: 1468\n",
            "loss is: [[0.69263281]]\n",
            "iteration: 1469\n",
            "loss is: [[0.73955825]]\n",
            "iteration: 1470\n",
            "loss is: [[0.69479657]]\n",
            "iteration: 1471\n",
            "loss is: [[0.68166237]]\n",
            "iteration: 1472\n",
            "loss is: [[0.69715354]]\n",
            "iteration: 1473\n",
            "loss is: [[0.69720493]]\n",
            "iteration: 1474\n",
            "loss is: [[0.6862924]]\n",
            "iteration: 1475\n",
            "loss is: [[0.70712482]]\n",
            "iteration: 1476\n",
            "loss is: [[0.68949639]]\n",
            "iteration: 1477\n",
            "loss is: [[0.69976547]]\n",
            "iteration: 1478\n",
            "loss is: [[0.67128063]]\n",
            "iteration: 1479\n",
            "loss is: [[0.67560072]]\n",
            "iteration: 1480\n",
            "loss is: [[0.66352151]]\n",
            "iteration: 1481\n",
            "loss is: [[0.68350901]]\n",
            "iteration: 1482\n",
            "loss is: [[0.70953015]]\n",
            "iteration: 1483\n",
            "loss is: [[0.69155525]]\n",
            "iteration: 1484\n",
            "loss is: [[0.67467926]]\n",
            "iteration: 1485\n",
            "loss is: [[0.6742404]]\n",
            "iteration: 1486\n",
            "loss is: [[0.68428005]]\n",
            "iteration: 1487\n",
            "loss is: [[0.70034608]]\n",
            "iteration: 1488\n",
            "loss is: [[0.66483328]]\n",
            "iteration: 1489\n",
            "loss is: [[0.69095967]]\n",
            "iteration: 1490\n",
            "loss is: [[0.73294461]]\n",
            "iteration: 1491\n",
            "loss is: [[0.67412604]]\n",
            "iteration: 1492\n",
            "loss is: [[0.67239848]]\n",
            "iteration: 1493\n",
            "loss is: [[0.67593082]]\n",
            "iteration: 1494\n",
            "loss is: [[0.68251381]]\n",
            "iteration: 1495\n",
            "loss is: [[0.73450387]]\n",
            "iteration: 1496\n",
            "loss is: [[0.7064982]]\n",
            "iteration: 1497\n",
            "loss is: [[0.68057594]]\n",
            "iteration: 1498\n",
            "loss is: [[0.69915062]]\n",
            "iteration: 1499\n",
            "loss is: [[0.69461483]]\n",
            "iteration: 1500\n",
            "loss is: [[0.63670197]]\n",
            "iteration: 1501\n",
            "loss is: [[0.64922263]]\n",
            "iteration: 1502\n",
            "loss is: [[0.68456788]]\n",
            "iteration: 1503\n",
            "loss is: [[0.66033329]]\n",
            "iteration: 1504\n",
            "loss is: [[0.67807814]]\n",
            "iteration: 1505\n",
            "loss is: [[0.72000288]]\n",
            "iteration: 1506\n",
            "loss is: [[0.66384821]]\n",
            "iteration: 1507\n",
            "loss is: [[0.67264549]]\n",
            "iteration: 1508\n",
            "loss is: [[0.68417293]]\n",
            "iteration: 1509\n",
            "loss is: [[0.68510584]]\n",
            "iteration: 1510\n",
            "loss is: [[0.66303668]]\n",
            "iteration: 1511\n",
            "loss is: [[0.65430466]]\n",
            "iteration: 1512\n",
            "loss is: [[0.68765835]]\n",
            "iteration: 1513\n",
            "loss is: [[0.64878274]]\n",
            "iteration: 1514\n",
            "loss is: [[0.71682479]]\n",
            "iteration: 1515\n",
            "loss is: [[0.65592304]]\n",
            "iteration: 1516\n",
            "loss is: [[0.67788541]]\n",
            "iteration: 1517\n",
            "loss is: [[0.67839628]]\n",
            "iteration: 1518\n",
            "loss is: [[0.69392628]]\n",
            "iteration: 1519\n",
            "loss is: [[0.67543212]]\n",
            "iteration: 1520\n",
            "loss is: [[0.66369877]]\n",
            "iteration: 1521\n",
            "loss is: [[0.66694552]]\n",
            "iteration: 1522\n",
            "loss is: [[0.69169017]]\n",
            "iteration: 1523\n",
            "loss is: [[0.67682808]]\n",
            "iteration: 1524\n",
            "loss is: [[0.68370246]]\n",
            "iteration: 1525\n",
            "loss is: [[0.69533454]]\n",
            "iteration: 1526\n",
            "loss is: [[0.69118024]]\n",
            "iteration: 1527\n",
            "loss is: [[0.71079792]]\n",
            "iteration: 1528\n",
            "loss is: [[0.69069864]]\n",
            "iteration: 1529\n",
            "loss is: [[0.67274786]]\n",
            "iteration: 1530\n",
            "loss is: [[0.65051292]]\n",
            "iteration: 1531\n",
            "loss is: [[0.66495146]]\n",
            "iteration: 1532\n",
            "loss is: [[0.66839368]]\n",
            "iteration: 1533\n",
            "loss is: [[0.66269564]]\n",
            "iteration: 1534\n",
            "loss is: [[0.66929148]]\n",
            "iteration: 1535\n",
            "loss is: [[0.67153514]]\n",
            "iteration: 1536\n",
            "loss is: [[0.6879298]]\n",
            "iteration: 1537\n",
            "loss is: [[0.69411156]]\n",
            "iteration: 1538\n",
            "loss is: [[0.69299991]]\n",
            "iteration: 1539\n",
            "loss is: [[0.69394343]]\n",
            "iteration: 1540\n",
            "loss is: [[0.72531495]]\n",
            "iteration: 1541\n",
            "loss is: [[0.68779813]]\n",
            "iteration: 1542\n",
            "loss is: [[0.67976358]]\n",
            "iteration: 1543\n",
            "loss is: [[0.72517275]]\n",
            "iteration: 1544\n",
            "loss is: [[0.67052521]]\n",
            "iteration: 1545\n",
            "loss is: [[0.68068209]]\n",
            "iteration: 1546\n",
            "loss is: [[0.71580701]]\n",
            "iteration: 1547\n",
            "loss is: [[0.71199472]]\n",
            "iteration: 1548\n",
            "loss is: [[0.68568563]]\n",
            "iteration: 1549\n",
            "loss is: [[0.69783718]]\n",
            "iteration: 1550\n",
            "loss is: [[0.68156724]]\n",
            "iteration: 1551\n",
            "loss is: [[0.69867132]]\n",
            "iteration: 1552\n",
            "loss is: [[0.69746744]]\n",
            "iteration: 1553\n",
            "loss is: [[0.70424735]]\n",
            "iteration: 1554\n",
            "loss is: [[0.67628775]]\n",
            "iteration: 1555\n",
            "loss is: [[0.69805869]]\n",
            "iteration: 1556\n",
            "loss is: [[0.68404797]]\n",
            "iteration: 1557\n",
            "loss is: [[0.65017889]]\n",
            "iteration: 1558\n",
            "loss is: [[0.70929826]]\n",
            "iteration: 1559\n",
            "loss is: [[0.72630885]]\n",
            "iteration: 1560\n",
            "loss is: [[0.70966722]]\n",
            "iteration: 1561\n",
            "loss is: [[0.66214634]]\n",
            "iteration: 1562\n",
            "loss is: [[0.66580991]]\n",
            "iteration: 1563\n",
            "loss is: [[0.71899888]]\n",
            "iteration: 1564\n",
            "loss is: [[0.70043571]]\n",
            "iteration: 1565\n",
            "loss is: [[0.65337852]]\n",
            "iteration: 1566\n",
            "loss is: [[0.68012708]]\n",
            "iteration: 1567\n",
            "loss is: [[0.66271725]]\n",
            "iteration: 1568\n",
            "loss is: [[0.69119474]]\n",
            "iteration: 1569\n",
            "loss is: [[0.68564497]]\n",
            "iteration: 1570\n",
            "loss is: [[0.70987811]]\n",
            "iteration: 1571\n",
            "loss is: [[0.68742593]]\n",
            "iteration: 1572\n",
            "loss is: [[0.71634778]]\n",
            "iteration: 1573\n",
            "loss is: [[0.70081263]]\n",
            "iteration: 1574\n",
            "loss is: [[0.69388105]]\n",
            "iteration: 1575\n",
            "loss is: [[0.69315044]]\n",
            "iteration: 1576\n",
            "loss is: [[0.67915706]]\n",
            "iteration: 1577\n",
            "loss is: [[0.68320013]]\n",
            "iteration: 1578\n",
            "loss is: [[0.70240184]]\n",
            "iteration: 1579\n",
            "loss is: [[0.70648662]]\n",
            "iteration: 1580\n",
            "loss is: [[0.69092843]]\n",
            "iteration: 1581\n",
            "loss is: [[0.67566727]]\n",
            "iteration: 1582\n",
            "loss is: [[0.67963553]]\n",
            "iteration: 1583\n",
            "loss is: [[0.68756136]]\n",
            "iteration: 1584\n",
            "loss is: [[0.69577619]]\n",
            "iteration: 1585\n",
            "loss is: [[0.70978891]]\n",
            "iteration: 1586\n",
            "loss is: [[0.70414778]]\n",
            "iteration: 1587\n",
            "loss is: [[0.69089089]]\n",
            "iteration: 1588\n",
            "loss is: [[0.70705932]]\n",
            "iteration: 1589\n",
            "loss is: [[0.70967176]]\n",
            "iteration: 1590\n",
            "loss is: [[0.67151453]]\n",
            "iteration: 1591\n",
            "loss is: [[0.69119191]]\n",
            "iteration: 1592\n",
            "loss is: [[0.7080967]]\n",
            "iteration: 1593\n",
            "loss is: [[0.69181666]]\n",
            "iteration: 1594\n",
            "loss is: [[0.68370067]]\n",
            "iteration: 1595\n",
            "loss is: [[0.67408418]]\n",
            "iteration: 1596\n",
            "loss is: [[0.70469779]]\n",
            "iteration: 1597\n",
            "loss is: [[0.68431787]]\n",
            "iteration: 1598\n",
            "loss is: [[0.68198755]]\n",
            "iteration: 1599\n",
            "loss is: [[0.67319184]]\n",
            "iteration: 1600\n",
            "loss is: [[0.67222414]]\n",
            "iteration: 1601\n",
            "loss is: [[0.67539281]]\n",
            "iteration: 1602\n",
            "loss is: [[0.71045393]]\n",
            "iteration: 1603\n",
            "loss is: [[0.6852021]]\n",
            "iteration: 1604\n",
            "loss is: [[0.67734831]]\n",
            "iteration: 1605\n",
            "loss is: [[0.70037977]]\n",
            "iteration: 1606\n",
            "loss is: [[0.67786226]]\n",
            "iteration: 1607\n",
            "loss is: [[0.70065635]]\n",
            "iteration: 1608\n",
            "loss is: [[0.69214852]]\n",
            "iteration: 1609\n",
            "loss is: [[0.70585993]]\n",
            "iteration: 1610\n",
            "loss is: [[0.6893611]]\n",
            "iteration: 1611\n",
            "loss is: [[0.74236382]]\n",
            "iteration: 1612\n",
            "loss is: [[0.67596955]]\n",
            "iteration: 1613\n",
            "loss is: [[0.67537239]]\n",
            "iteration: 1614\n",
            "loss is: [[0.72889483]]\n",
            "iteration: 1615\n",
            "loss is: [[0.69353489]]\n",
            "iteration: 1616\n",
            "loss is: [[0.6826274]]\n",
            "iteration: 1617\n",
            "loss is: [[0.70418026]]\n",
            "iteration: 1618\n",
            "loss is: [[0.68202576]]\n",
            "iteration: 1619\n",
            "loss is: [[0.67371068]]\n",
            "iteration: 1620\n",
            "loss is: [[0.68147061]]\n",
            "iteration: 1621\n",
            "loss is: [[0.64792477]]\n",
            "iteration: 1622\n",
            "loss is: [[0.68207637]]\n",
            "iteration: 1623\n",
            "loss is: [[0.68728787]]\n",
            "iteration: 1624\n",
            "loss is: [[0.68699002]]\n",
            "iteration: 1625\n",
            "loss is: [[0.70935284]]\n",
            "iteration: 1626\n",
            "loss is: [[0.68896998]]\n",
            "iteration: 1627\n",
            "loss is: [[0.65133016]]\n",
            "iteration: 1628\n",
            "loss is: [[0.68479647]]\n",
            "iteration: 1629\n",
            "loss is: [[0.7320161]]\n",
            "iteration: 1630\n",
            "loss is: [[0.68356438]]\n",
            "iteration: 1631\n",
            "loss is: [[0.6724917]]\n",
            "iteration: 1632\n",
            "loss is: [[0.69394722]]\n",
            "iteration: 1633\n",
            "loss is: [[0.67811606]]\n",
            "iteration: 1634\n",
            "loss is: [[0.67520907]]\n",
            "iteration: 1635\n",
            "loss is: [[0.67832209]]\n",
            "iteration: 1636\n",
            "loss is: [[0.65391824]]\n",
            "iteration: 1637\n",
            "loss is: [[0.68118458]]\n",
            "iteration: 1638\n",
            "loss is: [[0.65706029]]\n",
            "iteration: 1639\n",
            "loss is: [[0.66530191]]\n",
            "iteration: 1640\n",
            "loss is: [[0.66610482]]\n",
            "iteration: 1641\n",
            "loss is: [[0.71204229]]\n",
            "iteration: 1642\n",
            "loss is: [[0.68018283]]\n",
            "iteration: 1643\n",
            "loss is: [[0.67079503]]\n",
            "iteration: 1644\n",
            "loss is: [[0.68698349]]\n",
            "iteration: 1645\n",
            "loss is: [[0.67974608]]\n",
            "iteration: 1646\n",
            "loss is: [[0.68355956]]\n",
            "iteration: 1647\n",
            "loss is: [[0.66986092]]\n",
            "iteration: 1648\n",
            "loss is: [[0.67378835]]\n",
            "iteration: 1649\n",
            "loss is: [[0.70619091]]\n",
            "iteration: 1650\n",
            "loss is: [[0.70196453]]\n",
            "iteration: 1651\n",
            "loss is: [[0.71010953]]\n",
            "iteration: 1652\n",
            "loss is: [[0.71272608]]\n",
            "iteration: 1653\n",
            "loss is: [[0.69158868]]\n",
            "iteration: 1654\n",
            "loss is: [[0.69589363]]\n",
            "iteration: 1655\n",
            "loss is: [[0.68570648]]\n",
            "iteration: 1656\n",
            "loss is: [[0.67269087]]\n",
            "iteration: 1657\n",
            "loss is: [[0.67013486]]\n",
            "iteration: 1658\n",
            "loss is: [[0.66815176]]\n",
            "iteration: 1659\n",
            "loss is: [[0.72022372]]\n",
            "iteration: 1660\n",
            "loss is: [[0.66391448]]\n",
            "iteration: 1661\n",
            "loss is: [[0.67877214]]\n",
            "iteration: 1662\n",
            "loss is: [[0.67691724]]\n",
            "iteration: 1663\n",
            "loss is: [[0.69023179]]\n",
            "iteration: 1664\n",
            "loss is: [[0.68164056]]\n",
            "iteration: 1665\n",
            "loss is: [[0.68132688]]\n",
            "iteration: 1666\n",
            "loss is: [[0.67430143]]\n",
            "iteration: 1667\n",
            "loss is: [[0.68357669]]\n",
            "iteration: 1668\n",
            "loss is: [[0.67683148]]\n",
            "iteration: 1669\n",
            "loss is: [[0.67651086]]\n",
            "iteration: 1670\n",
            "loss is: [[0.6822008]]\n",
            "iteration: 1671\n",
            "loss is: [[0.66670292]]\n",
            "iteration: 1672\n",
            "loss is: [[0.71426047]]\n",
            "iteration: 1673\n",
            "loss is: [[0.66554417]]\n",
            "iteration: 1674\n",
            "loss is: [[0.67295085]]\n",
            "iteration: 1675\n",
            "loss is: [[0.68949108]]\n",
            "iteration: 1676\n",
            "loss is: [[0.67913054]]\n",
            "iteration: 1677\n",
            "loss is: [[0.69779242]]\n",
            "iteration: 1678\n",
            "loss is: [[0.6848208]]\n",
            "iteration: 1679\n",
            "loss is: [[0.70286868]]\n",
            "iteration: 1680\n",
            "loss is: [[0.71354415]]\n",
            "iteration: 1681\n",
            "loss is: [[0.66410861]]\n",
            "iteration: 1682\n",
            "loss is: [[0.67496807]]\n",
            "iteration: 1683\n",
            "loss is: [[0.69595836]]\n",
            "iteration: 1684\n",
            "loss is: [[0.67105496]]\n",
            "iteration: 1685\n",
            "loss is: [[0.69277657]]\n",
            "iteration: 1686\n",
            "loss is: [[0.67671343]]\n",
            "iteration: 1687\n",
            "loss is: [[0.65918824]]\n",
            "iteration: 1688\n",
            "loss is: [[0.66627511]]\n",
            "iteration: 1689\n",
            "loss is: [[0.67688029]]\n",
            "iteration: 1690\n",
            "loss is: [[0.68218082]]\n",
            "iteration: 1691\n",
            "loss is: [[0.70592358]]\n",
            "iteration: 1692\n",
            "loss is: [[0.64382934]]\n",
            "iteration: 1693\n",
            "loss is: [[0.69646391]]\n",
            "iteration: 1694\n",
            "loss is: [[0.67892269]]\n",
            "iteration: 1695\n",
            "loss is: [[0.7168375]]\n",
            "iteration: 1696\n",
            "loss is: [[0.66640631]]\n",
            "iteration: 1697\n",
            "loss is: [[0.67933615]]\n",
            "iteration: 1698\n",
            "loss is: [[0.67112827]]\n",
            "iteration: 1699\n",
            "loss is: [[0.69491107]]\n",
            "iteration: 1700\n",
            "loss is: [[0.74776222]]\n",
            "iteration: 1701\n",
            "loss is: [[0.66965982]]\n",
            "iteration: 1702\n",
            "loss is: [[0.69216545]]\n",
            "iteration: 1703\n",
            "loss is: [[0.66213672]]\n",
            "iteration: 1704\n",
            "loss is: [[0.70352406]]\n",
            "iteration: 1705\n",
            "loss is: [[0.66899132]]\n",
            "iteration: 1706\n",
            "loss is: [[0.68950238]]\n",
            "iteration: 1707\n",
            "loss is: [[0.68210667]]\n",
            "iteration: 1708\n",
            "loss is: [[0.69235207]]\n",
            "iteration: 1709\n",
            "loss is: [[0.71022826]]\n",
            "iteration: 1710\n",
            "loss is: [[0.70310237]]\n",
            "iteration: 1711\n",
            "loss is: [[0.6794719]]\n",
            "iteration: 1712\n",
            "loss is: [[0.65161715]]\n",
            "iteration: 1713\n",
            "loss is: [[0.70944082]]\n",
            "iteration: 1714\n",
            "loss is: [[0.67672209]]\n",
            "iteration: 1715\n",
            "loss is: [[0.67130515]]\n",
            "iteration: 1716\n",
            "loss is: [[0.67282329]]\n",
            "iteration: 1717\n",
            "loss is: [[0.71092432]]\n",
            "iteration: 1718\n",
            "loss is: [[0.72334699]]\n",
            "iteration: 1719\n",
            "loss is: [[0.66066087]]\n",
            "iteration: 1720\n",
            "loss is: [[0.6941974]]\n",
            "iteration: 1721\n",
            "loss is: [[0.67088625]]\n",
            "iteration: 1722\n",
            "loss is: [[0.63188187]]\n",
            "iteration: 1723\n",
            "loss is: [[0.67763134]]\n",
            "iteration: 1724\n",
            "loss is: [[0.6974389]]\n",
            "iteration: 1725\n",
            "loss is: [[0.65112886]]\n",
            "iteration: 1726\n",
            "loss is: [[0.67009036]]\n",
            "iteration: 1727\n",
            "loss is: [[0.6482453]]\n",
            "iteration: 1728\n",
            "loss is: [[0.69920853]]\n",
            "iteration: 1729\n",
            "loss is: [[0.64572033]]\n",
            "iteration: 1730\n",
            "loss is: [[0.64784495]]\n",
            "iteration: 1731\n",
            "loss is: [[0.67407564]]\n",
            "iteration: 1732\n",
            "loss is: [[0.64141503]]\n",
            "iteration: 1733\n",
            "loss is: [[0.71387826]]\n",
            "iteration: 1734\n",
            "loss is: [[0.67928245]]\n",
            "iteration: 1735\n",
            "loss is: [[0.67800908]]\n",
            "iteration: 1736\n",
            "loss is: [[0.67911286]]\n",
            "iteration: 1737\n",
            "loss is: [[0.66898349]]\n",
            "iteration: 1738\n",
            "loss is: [[0.67271806]]\n",
            "iteration: 1739\n",
            "loss is: [[0.65952386]]\n",
            "iteration: 1740\n",
            "loss is: [[0.67256074]]\n",
            "iteration: 1741\n",
            "loss is: [[0.65116871]]\n",
            "iteration: 1742\n",
            "loss is: [[0.68945135]]\n",
            "iteration: 1743\n",
            "loss is: [[0.69085292]]\n",
            "iteration: 1744\n",
            "loss is: [[0.67009208]]\n",
            "iteration: 1745\n",
            "loss is: [[0.69040591]]\n",
            "iteration: 1746\n",
            "loss is: [[0.63543255]]\n",
            "iteration: 1747\n",
            "loss is: [[0.65927644]]\n",
            "iteration: 1748\n",
            "loss is: [[0.68573212]]\n",
            "iteration: 1749\n",
            "loss is: [[0.6629424]]\n",
            "iteration: 1750\n",
            "loss is: [[0.72166168]]\n",
            "iteration: 1751\n",
            "loss is: [[0.70819657]]\n",
            "iteration: 1752\n",
            "loss is: [[0.64676878]]\n",
            "iteration: 1753\n",
            "loss is: [[0.7022641]]\n",
            "iteration: 1754\n",
            "loss is: [[0.70110483]]\n",
            "iteration: 1755\n",
            "loss is: [[0.67703231]]\n",
            "iteration: 1756\n",
            "loss is: [[0.71791887]]\n",
            "iteration: 1757\n",
            "loss is: [[0.69102456]]\n",
            "iteration: 1758\n",
            "loss is: [[0.70468656]]\n",
            "iteration: 1759\n",
            "loss is: [[0.67958008]]\n",
            "iteration: 1760\n",
            "loss is: [[0.67166995]]\n",
            "iteration: 1761\n",
            "loss is: [[0.66966847]]\n",
            "iteration: 1762\n",
            "loss is: [[0.71655563]]\n",
            "iteration: 1763\n",
            "loss is: [[0.69284125]]\n",
            "iteration: 1764\n",
            "loss is: [[0.65999623]]\n",
            "iteration: 1765\n",
            "loss is: [[0.70429549]]\n",
            "iteration: 1766\n",
            "loss is: [[0.73628764]]\n",
            "iteration: 1767\n",
            "loss is: [[0.73809614]]\n",
            "iteration: 1768\n",
            "loss is: [[0.71853773]]\n",
            "iteration: 1769\n",
            "loss is: [[0.68540892]]\n",
            "iteration: 1770\n",
            "loss is: [[0.65674738]]\n",
            "iteration: 1771\n",
            "loss is: [[0.69021101]]\n",
            "iteration: 1772\n",
            "loss is: [[0.69536143]]\n",
            "iteration: 1773\n",
            "loss is: [[0.68997176]]\n",
            "iteration: 1774\n",
            "loss is: [[0.6785776]]\n",
            "iteration: 1775\n",
            "loss is: [[0.67277931]]\n",
            "iteration: 1776\n",
            "loss is: [[0.69941177]]\n",
            "iteration: 1777\n",
            "loss is: [[0.73136795]]\n",
            "iteration: 1778\n",
            "loss is: [[0.67054524]]\n",
            "iteration: 1779\n",
            "loss is: [[0.68200492]]\n",
            "iteration: 1780\n",
            "loss is: [[0.68336928]]\n",
            "iteration: 1781\n",
            "loss is: [[0.67363612]]\n",
            "iteration: 1782\n",
            "loss is: [[0.65047129]]\n",
            "iteration: 1783\n",
            "loss is: [[0.655016]]\n",
            "iteration: 1784\n",
            "loss is: [[0.6657861]]\n",
            "iteration: 1785\n",
            "loss is: [[0.66916799]]\n",
            "iteration: 1786\n",
            "loss is: [[0.67883828]]\n",
            "iteration: 1787\n",
            "loss is: [[0.71323047]]\n",
            "iteration: 1788\n",
            "loss is: [[0.67311141]]\n",
            "iteration: 1789\n",
            "loss is: [[0.69675381]]\n",
            "iteration: 1790\n",
            "loss is: [[0.68973972]]\n",
            "iteration: 1791\n",
            "loss is: [[0.68338726]]\n",
            "iteration: 1792\n",
            "loss is: [[0.71561614]]\n",
            "iteration: 1793\n",
            "loss is: [[0.70654324]]\n",
            "iteration: 1794\n",
            "loss is: [[0.69242183]]\n",
            "iteration: 1795\n",
            "loss is: [[0.73377505]]\n",
            "iteration: 1796\n",
            "loss is: [[0.71000775]]\n",
            "iteration: 1797\n",
            "loss is: [[0.71863529]]\n",
            "iteration: 1798\n",
            "loss is: [[0.70445731]]\n",
            "iteration: 1799\n",
            "loss is: [[0.69583609]]\n",
            "iteration: 1800\n",
            "loss is: [[0.70117312]]\n",
            "iteration: 1801\n",
            "loss is: [[0.71595474]]\n",
            "iteration: 1802\n",
            "loss is: [[0.71318646]]\n",
            "iteration: 1803\n",
            "loss is: [[0.70843977]]\n",
            "iteration: 1804\n",
            "loss is: [[0.71662279]]\n",
            "iteration: 1805\n",
            "loss is: [[0.68485063]]\n",
            "iteration: 1806\n",
            "loss is: [[0.6886962]]\n",
            "iteration: 1807\n",
            "loss is: [[0.68849939]]\n",
            "iteration: 1808\n",
            "loss is: [[0.67104461]]\n",
            "iteration: 1809\n",
            "loss is: [[0.67775808]]\n",
            "iteration: 1810\n",
            "loss is: [[0.65075799]]\n",
            "iteration: 1811\n",
            "loss is: [[0.67179569]]\n",
            "iteration: 1812\n",
            "loss is: [[0.71333595]]\n",
            "iteration: 1813\n",
            "loss is: [[0.65814106]]\n",
            "iteration: 1814\n",
            "loss is: [[0.69222092]]\n",
            "iteration: 1815\n",
            "loss is: [[0.65486722]]\n",
            "iteration: 1816\n",
            "loss is: [[0.69829966]]\n",
            "iteration: 1817\n",
            "loss is: [[0.70719191]]\n",
            "iteration: 1818\n",
            "loss is: [[0.68121187]]\n",
            "iteration: 1819\n",
            "loss is: [[0.66856996]]\n",
            "iteration: 1820\n",
            "loss is: [[0.68275989]]\n",
            "iteration: 1821\n",
            "loss is: [[0.68796543]]\n",
            "iteration: 1822\n",
            "loss is: [[0.66917958]]\n",
            "iteration: 1823\n",
            "loss is: [[0.68908575]]\n",
            "iteration: 1824\n",
            "loss is: [[0.64321983]]\n",
            "iteration: 1825\n",
            "loss is: [[0.67039963]]\n",
            "iteration: 1826\n",
            "loss is: [[0.67990954]]\n",
            "iteration: 1827\n",
            "loss is: [[0.67504632]]\n",
            "iteration: 1828\n",
            "loss is: [[0.63640834]]\n",
            "iteration: 1829\n",
            "loss is: [[0.69668903]]\n",
            "iteration: 1830\n",
            "loss is: [[0.6725531]]\n",
            "iteration: 1831\n",
            "loss is: [[0.65989671]]\n",
            "iteration: 1832\n",
            "loss is: [[0.67129505]]\n",
            "iteration: 1833\n",
            "loss is: [[0.65623347]]\n",
            "iteration: 1834\n",
            "loss is: [[0.67616827]]\n",
            "iteration: 1835\n",
            "loss is: [[0.70064035]]\n",
            "iteration: 1836\n",
            "loss is: [[0.68135277]]\n",
            "iteration: 1837\n",
            "loss is: [[0.68839267]]\n",
            "iteration: 1838\n",
            "loss is: [[0.69864911]]\n",
            "iteration: 1839\n",
            "loss is: [[0.68525529]]\n",
            "iteration: 1840\n",
            "loss is: [[0.68693993]]\n",
            "iteration: 1841\n",
            "loss is: [[0.68434731]]\n",
            "iteration: 1842\n",
            "loss is: [[0.6925546]]\n",
            "iteration: 1843\n",
            "loss is: [[0.71220306]]\n",
            "iteration: 1844\n",
            "loss is: [[0.68234417]]\n",
            "iteration: 1845\n",
            "loss is: [[0.7002683]]\n",
            "iteration: 1846\n",
            "loss is: [[0.68078887]]\n",
            "iteration: 1847\n",
            "loss is: [[0.63327559]]\n",
            "iteration: 1848\n",
            "loss is: [[0.67280698]]\n",
            "iteration: 1849\n",
            "loss is: [[0.67086487]]\n",
            "iteration: 1850\n",
            "loss is: [[0.67366197]]\n",
            "iteration: 1851\n",
            "loss is: [[0.68541208]]\n",
            "iteration: 1852\n",
            "loss is: [[0.67976159]]\n",
            "iteration: 1853\n",
            "loss is: [[0.68474626]]\n",
            "iteration: 1854\n",
            "loss is: [[0.67945868]]\n",
            "iteration: 1855\n",
            "loss is: [[0.66269086]]\n",
            "iteration: 1856\n",
            "loss is: [[0.65922813]]\n",
            "iteration: 1857\n",
            "loss is: [[0.64607024]]\n",
            "iteration: 1858\n",
            "loss is: [[0.66994245]]\n",
            "iteration: 1859\n",
            "loss is: [[0.67072645]]\n",
            "iteration: 1860\n",
            "loss is: [[0.66306462]]\n",
            "iteration: 1861\n",
            "loss is: [[0.67650956]]\n",
            "iteration: 1862\n",
            "loss is: [[0.70087315]]\n",
            "iteration: 1863\n",
            "loss is: [[0.65861315]]\n",
            "iteration: 1864\n",
            "loss is: [[0.71094182]]\n",
            "iteration: 1865\n",
            "loss is: [[0.66313178]]\n",
            "iteration: 1866\n",
            "loss is: [[0.70014184]]\n",
            "iteration: 1867\n",
            "loss is: [[0.68753205]]\n",
            "iteration: 1868\n",
            "loss is: [[0.71026725]]\n",
            "iteration: 1869\n",
            "loss is: [[0.72445146]]\n",
            "iteration: 1870\n",
            "loss is: [[0.69153759]]\n",
            "iteration: 1871\n",
            "loss is: [[0.68534211]]\n",
            "iteration: 1872\n",
            "loss is: [[0.71867504]]\n",
            "iteration: 1873\n",
            "loss is: [[0.67572166]]\n",
            "iteration: 1874\n",
            "loss is: [[0.67606549]]\n",
            "iteration: 1875\n",
            "loss is: [[0.69147837]]\n",
            "iteration: 1876\n",
            "loss is: [[0.67321993]]\n",
            "iteration: 1877\n",
            "loss is: [[0.68816813]]\n",
            "iteration: 1878\n",
            "loss is: [[0.67212371]]\n",
            "iteration: 1879\n",
            "loss is: [[0.65213037]]\n",
            "iteration: 1880\n",
            "loss is: [[0.68038947]]\n",
            "iteration: 1881\n",
            "loss is: [[0.68091569]]\n",
            "iteration: 1882\n",
            "loss is: [[0.67338393]]\n",
            "iteration: 1883\n",
            "loss is: [[0.67587541]]\n",
            "iteration: 1884\n",
            "loss is: [[0.6450947]]\n",
            "iteration: 1885\n",
            "loss is: [[0.6491209]]\n",
            "iteration: 1886\n",
            "loss is: [[0.66744411]]\n",
            "iteration: 1887\n",
            "loss is: [[0.69605414]]\n",
            "iteration: 1888\n",
            "loss is: [[0.6567373]]\n",
            "iteration: 1889\n",
            "loss is: [[0.73005286]]\n",
            "iteration: 1890\n",
            "loss is: [[0.70977853]]\n",
            "iteration: 1891\n",
            "loss is: [[0.68756356]]\n",
            "iteration: 1892\n",
            "loss is: [[0.68939894]]\n",
            "iteration: 1893\n",
            "loss is: [[0.70625199]]\n",
            "iteration: 1894\n",
            "loss is: [[0.65361991]]\n",
            "iteration: 1895\n",
            "loss is: [[0.68541075]]\n",
            "iteration: 1896\n",
            "loss is: [[0.68437413]]\n",
            "iteration: 1897\n",
            "loss is: [[0.68825437]]\n",
            "iteration: 1898\n",
            "loss is: [[0.66370828]]\n",
            "iteration: 1899\n",
            "loss is: [[0.67013203]]\n",
            "iteration: 1900\n",
            "loss is: [[0.68025738]]\n",
            "iteration: 1901\n",
            "loss is: [[0.64508774]]\n",
            "iteration: 1902\n",
            "loss is: [[0.66908448]]\n",
            "iteration: 1903\n",
            "loss is: [[0.70223338]]\n",
            "iteration: 1904\n",
            "loss is: [[0.71679986]]\n",
            "iteration: 1905\n",
            "loss is: [[0.69612504]]\n",
            "iteration: 1906\n",
            "loss is: [[0.73706013]]\n",
            "iteration: 1907\n",
            "loss is: [[0.69338785]]\n",
            "iteration: 1908\n",
            "loss is: [[0.70111552]]\n",
            "iteration: 1909\n",
            "loss is: [[0.69519471]]\n",
            "iteration: 1910\n",
            "loss is: [[0.66183682]]\n",
            "iteration: 1911\n",
            "loss is: [[0.68544799]]\n",
            "iteration: 1912\n",
            "loss is: [[0.68425389]]\n",
            "iteration: 1913\n",
            "loss is: [[0.63624107]]\n",
            "iteration: 1914\n",
            "loss is: [[0.68413776]]\n",
            "iteration: 1915\n",
            "loss is: [[0.65807493]]\n",
            "iteration: 1916\n",
            "loss is: [[0.70105683]]\n",
            "iteration: 1917\n",
            "loss is: [[0.66529778]]\n",
            "iteration: 1918\n",
            "loss is: [[0.70516333]]\n",
            "iteration: 1919\n",
            "loss is: [[0.67605341]]\n",
            "iteration: 1920\n",
            "loss is: [[0.68853952]]\n",
            "iteration: 1921\n",
            "loss is: [[0.68894145]]\n",
            "iteration: 1922\n",
            "loss is: [[0.67771965]]\n",
            "iteration: 1923\n",
            "loss is: [[0.64244738]]\n",
            "iteration: 1924\n",
            "loss is: [[0.66018744]]\n",
            "iteration: 1925\n",
            "loss is: [[0.67699338]]\n",
            "iteration: 1926\n",
            "loss is: [[0.65608871]]\n",
            "iteration: 1927\n",
            "loss is: [[0.66307163]]\n",
            "iteration: 1928\n",
            "loss is: [[0.69376186]]\n",
            "iteration: 1929\n",
            "loss is: [[0.67763179]]\n",
            "iteration: 1930\n",
            "loss is: [[0.65717166]]\n",
            "iteration: 1931\n",
            "loss is: [[0.68211981]]\n",
            "iteration: 1932\n",
            "loss is: [[0.67263677]]\n",
            "iteration: 1933\n",
            "loss is: [[0.67632105]]\n",
            "iteration: 1934\n",
            "loss is: [[0.70838879]]\n",
            "iteration: 1935\n",
            "loss is: [[0.75515995]]\n",
            "iteration: 1936\n",
            "loss is: [[0.73346549]]\n",
            "iteration: 1937\n",
            "loss is: [[0.68645038]]\n",
            "iteration: 1938\n",
            "loss is: [[0.70013516]]\n",
            "iteration: 1939\n",
            "loss is: [[0.67131019]]\n",
            "iteration: 1940\n",
            "loss is: [[0.64850187]]\n",
            "iteration: 1941\n",
            "loss is: [[0.69473239]]\n",
            "iteration: 1942\n",
            "loss is: [[0.70963444]]\n",
            "iteration: 1943\n",
            "loss is: [[0.67645973]]\n",
            "iteration: 1944\n",
            "loss is: [[0.65756652]]\n",
            "iteration: 1945\n",
            "loss is: [[0.68406565]]\n",
            "iteration: 1946\n",
            "loss is: [[0.67184691]]\n",
            "iteration: 1947\n",
            "loss is: [[0.70954499]]\n",
            "iteration: 1948\n",
            "loss is: [[0.68276681]]\n",
            "iteration: 1949\n",
            "loss is: [[0.67047558]]\n",
            "iteration: 1950\n",
            "loss is: [[0.70078749]]\n",
            "iteration: 1951\n",
            "loss is: [[0.68130654]]\n",
            "iteration: 1952\n",
            "loss is: [[0.70501328]]\n",
            "iteration: 1953\n",
            "loss is: [[0.67296534]]\n",
            "iteration: 1954\n",
            "loss is: [[0.66289016]]\n",
            "iteration: 1955\n",
            "loss is: [[0.6902763]]\n",
            "iteration: 1956\n",
            "loss is: [[0.6737464]]\n",
            "iteration: 1957\n",
            "loss is: [[0.70930996]]\n",
            "iteration: 1958\n",
            "loss is: [[0.70892129]]\n",
            "iteration: 1959\n",
            "loss is: [[0.72788054]]\n",
            "iteration: 1960\n",
            "loss is: [[0.68278302]]\n",
            "iteration: 1961\n",
            "loss is: [[0.65198221]]\n",
            "iteration: 1962\n",
            "loss is: [[0.72494884]]\n",
            "iteration: 1963\n",
            "loss is: [[0.71925289]]\n",
            "iteration: 1964\n",
            "loss is: [[0.65006798]]\n",
            "iteration: 1965\n",
            "loss is: [[0.64533912]]\n",
            "iteration: 1966\n",
            "loss is: [[0.66388763]]\n",
            "iteration: 1967\n",
            "loss is: [[0.66658819]]\n",
            "iteration: 1968\n",
            "loss is: [[0.67161133]]\n",
            "iteration: 1969\n",
            "loss is: [[0.68582152]]\n",
            "iteration: 1970\n",
            "loss is: [[0.72294564]]\n",
            "iteration: 1971\n",
            "loss is: [[0.68920553]]\n",
            "iteration: 1972\n",
            "loss is: [[0.6707428]]\n",
            "iteration: 1973\n",
            "loss is: [[0.70762512]]\n",
            "iteration: 1974\n",
            "loss is: [[0.71033694]]\n",
            "iteration: 1975\n",
            "loss is: [[0.68099496]]\n",
            "iteration: 1976\n",
            "loss is: [[0.71231121]]\n",
            "iteration: 1977\n",
            "loss is: [[0.66759673]]\n",
            "iteration: 1978\n",
            "loss is: [[0.71477597]]\n",
            "iteration: 1979\n",
            "loss is: [[0.68841801]]\n",
            "iteration: 1980\n",
            "loss is: [[0.72243198]]\n",
            "iteration: 1981\n",
            "loss is: [[0.68837868]]\n",
            "iteration: 1982\n",
            "loss is: [[0.72036611]]\n",
            "iteration: 1983\n",
            "loss is: [[0.68997807]]\n",
            "iteration: 1984\n",
            "loss is: [[0.66265678]]\n",
            "iteration: 1985\n",
            "loss is: [[0.66918726]]\n",
            "iteration: 1986\n",
            "loss is: [[0.6836266]]\n",
            "iteration: 1987\n",
            "loss is: [[0.69906485]]\n",
            "iteration: 1988\n",
            "loss is: [[0.71378427]]\n",
            "iteration: 1989\n",
            "loss is: [[0.64659898]]\n",
            "iteration: 1990\n",
            "loss is: [[0.64785536]]\n",
            "iteration: 1991\n",
            "loss is: [[0.6767409]]\n",
            "iteration: 1992\n",
            "loss is: [[0.69285991]]\n",
            "iteration: 1993\n",
            "loss is: [[0.69432286]]\n",
            "iteration: 1994\n",
            "loss is: [[0.71373888]]\n",
            "iteration: 1995\n",
            "loss is: [[0.66956792]]\n",
            "iteration: 1996\n",
            "loss is: [[0.63793905]]\n",
            "iteration: 1997\n",
            "loss is: [[0.6934221]]\n",
            "iteration: 1998\n",
            "loss is: [[0.6652692]]\n",
            "iteration: 1999\n",
            "loss is: [[0.6823554]]\n",
            "iteration: 2000\n",
            "loss is: [[0.6679512]]\n",
            "iteration: 2001\n",
            "loss is: [[0.68521587]]\n",
            "iteration: 2002\n",
            "loss is: [[0.66583166]]\n",
            "iteration: 2003\n",
            "loss is: [[0.69598242]]\n",
            "iteration: 2004\n",
            "loss is: [[0.68613969]]\n",
            "iteration: 2005\n",
            "loss is: [[0.7640756]]\n",
            "iteration: 2006\n",
            "loss is: [[0.69774692]]\n",
            "iteration: 2007\n",
            "loss is: [[0.68990951]]\n",
            "iteration: 2008\n",
            "loss is: [[0.68068009]]\n",
            "iteration: 2009\n",
            "loss is: [[0.67930186]]\n",
            "iteration: 2010\n",
            "loss is: [[0.6775422]]\n",
            "iteration: 2011\n",
            "loss is: [[0.68436277]]\n",
            "iteration: 2012\n",
            "loss is: [[0.67564916]]\n",
            "iteration: 2013\n",
            "loss is: [[0.70585818]]\n",
            "iteration: 2014\n",
            "loss is: [[0.67073923]]\n",
            "iteration: 2015\n",
            "loss is: [[0.71133487]]\n",
            "iteration: 2016\n",
            "loss is: [[0.6845577]]\n",
            "iteration: 2017\n",
            "loss is: [[0.68598882]]\n",
            "iteration: 2018\n",
            "loss is: [[0.68273953]]\n",
            "iteration: 2019\n",
            "loss is: [[0.67774889]]\n",
            "iteration: 2020\n",
            "loss is: [[0.72547705]]\n",
            "iteration: 2021\n",
            "loss is: [[0.73239171]]\n",
            "iteration: 2022\n",
            "loss is: [[0.69678688]]\n",
            "iteration: 2023\n",
            "loss is: [[0.69494535]]\n",
            "iteration: 2024\n",
            "loss is: [[0.67997876]]\n",
            "iteration: 2025\n",
            "loss is: [[0.67091223]]\n",
            "iteration: 2026\n",
            "loss is: [[0.72397853]]\n",
            "iteration: 2027\n",
            "loss is: [[0.70657349]]\n",
            "iteration: 2028\n",
            "loss is: [[0.67962838]]\n",
            "iteration: 2029\n",
            "loss is: [[0.65231264]]\n",
            "iteration: 2030\n",
            "loss is: [[0.67168365]]\n",
            "iteration: 2031\n",
            "loss is: [[0.65967148]]\n",
            "iteration: 2032\n",
            "loss is: [[0.6836198]]\n",
            "iteration: 2033\n",
            "loss is: [[0.68088782]]\n",
            "iteration: 2034\n",
            "loss is: [[0.66842465]]\n",
            "iteration: 2035\n",
            "loss is: [[0.64739534]]\n",
            "iteration: 2036\n",
            "loss is: [[0.70685951]]\n",
            "iteration: 2037\n",
            "loss is: [[0.71174962]]\n",
            "iteration: 2038\n",
            "loss is: [[0.66102441]]\n",
            "iteration: 2039\n",
            "loss is: [[0.66157524]]\n",
            "iteration: 2040\n",
            "loss is: [[0.70191506]]\n",
            "iteration: 2041\n",
            "loss is: [[0.68284953]]\n",
            "iteration: 2042\n",
            "loss is: [[0.71919535]]\n",
            "iteration: 2043\n",
            "loss is: [[0.69768128]]\n",
            "iteration: 2044\n",
            "loss is: [[0.69416988]]\n",
            "iteration: 2045\n",
            "loss is: [[0.68262071]]\n",
            "iteration: 2046\n",
            "loss is: [[0.70357102]]\n",
            "iteration: 2047\n",
            "loss is: [[0.69450626]]\n",
            "iteration: 2048\n",
            "loss is: [[0.68520243]]\n",
            "iteration: 2049\n",
            "loss is: [[0.70073008]]\n",
            "iteration: 2050\n",
            "loss is: [[0.67031396]]\n",
            "iteration: 2051\n",
            "loss is: [[0.65000245]]\n",
            "iteration: 2052\n",
            "loss is: [[0.67839335]]\n",
            "iteration: 2053\n",
            "loss is: [[0.67371219]]\n",
            "iteration: 2054\n",
            "loss is: [[0.68423844]]\n",
            "iteration: 2055\n",
            "loss is: [[0.69691939]]\n",
            "iteration: 2056\n",
            "loss is: [[0.68469439]]\n",
            "iteration: 2057\n",
            "loss is: [[0.70269014]]\n",
            "iteration: 2058\n",
            "loss is: [[0.70465903]]\n",
            "iteration: 2059\n",
            "loss is: [[0.64519014]]\n",
            "iteration: 2060\n",
            "loss is: [[0.70721634]]\n",
            "iteration: 2061\n",
            "loss is: [[0.73389666]]\n",
            "iteration: 2062\n",
            "loss is: [[0.70597763]]\n",
            "iteration: 2063\n",
            "loss is: [[0.71567791]]\n",
            "iteration: 2064\n",
            "loss is: [[0.66597511]]\n",
            "iteration: 2065\n",
            "loss is: [[0.65893982]]\n",
            "iteration: 2066\n",
            "loss is: [[0.67580736]]\n",
            "iteration: 2067\n",
            "loss is: [[0.67331981]]\n",
            "iteration: 2068\n",
            "loss is: [[0.66574287]]\n",
            "iteration: 2069\n",
            "loss is: [[0.70270556]]\n",
            "iteration: 2070\n",
            "loss is: [[0.6817371]]\n",
            "iteration: 2071\n",
            "loss is: [[0.68551471]]\n",
            "iteration: 2072\n",
            "loss is: [[0.68315459]]\n",
            "iteration: 2073\n",
            "loss is: [[0.71013403]]\n",
            "iteration: 2074\n",
            "loss is: [[0.67150928]]\n",
            "iteration: 2075\n",
            "loss is: [[0.63735532]]\n",
            "iteration: 2076\n",
            "loss is: [[0.67887698]]\n",
            "iteration: 2077\n",
            "loss is: [[0.66902836]]\n",
            "iteration: 2078\n",
            "loss is: [[0.73512998]]\n",
            "iteration: 2079\n",
            "loss is: [[0.6923095]]\n",
            "iteration: 2080\n",
            "loss is: [[0.6728316]]\n",
            "iteration: 2081\n",
            "loss is: [[0.69883129]]\n",
            "iteration: 2082\n",
            "loss is: [[0.71465691]]\n",
            "iteration: 2083\n",
            "loss is: [[0.68600144]]\n",
            "iteration: 2084\n",
            "loss is: [[0.65640845]]\n",
            "iteration: 2085\n",
            "loss is: [[0.68282178]]\n",
            "iteration: 2086\n",
            "loss is: [[0.71094401]]\n",
            "iteration: 2087\n",
            "loss is: [[0.67508329]]\n",
            "iteration: 2088\n",
            "loss is: [[0.6560434]]\n",
            "iteration: 2089\n",
            "loss is: [[0.65971596]]\n",
            "iteration: 2090\n",
            "loss is: [[0.66408253]]\n",
            "iteration: 2091\n",
            "loss is: [[0.6851477]]\n",
            "iteration: 2092\n",
            "loss is: [[0.69605457]]\n",
            "iteration: 2093\n",
            "loss is: [[0.6714052]]\n",
            "iteration: 2094\n",
            "loss is: [[0.65474423]]\n",
            "iteration: 2095\n",
            "loss is: [[0.70367809]]\n",
            "iteration: 2096\n",
            "loss is: [[0.69457373]]\n",
            "iteration: 2097\n",
            "loss is: [[0.65632478]]\n",
            "iteration: 2098\n",
            "loss is: [[0.67457688]]\n",
            "iteration: 2099\n",
            "loss is: [[0.72388579]]\n",
            "iteration: 2100\n",
            "loss is: [[0.66342831]]\n",
            "iteration: 2101\n",
            "loss is: [[0.67894222]]\n",
            "iteration: 2102\n",
            "loss is: [[0.67143416]]\n",
            "iteration: 2103\n",
            "loss is: [[0.68786451]]\n",
            "iteration: 2104\n",
            "loss is: [[0.70879311]]\n",
            "iteration: 2105\n",
            "loss is: [[0.72890026]]\n",
            "iteration: 2106\n",
            "loss is: [[0.68550408]]\n",
            "iteration: 2107\n",
            "loss is: [[0.70200831]]\n",
            "iteration: 2108\n",
            "loss is: [[0.71335976]]\n",
            "iteration: 2109\n",
            "loss is: [[0.6879062]]\n",
            "iteration: 2110\n",
            "loss is: [[0.66447216]]\n",
            "iteration: 2111\n",
            "loss is: [[0.65695113]]\n",
            "iteration: 2112\n",
            "loss is: [[0.7260557]]\n",
            "iteration: 2113\n",
            "loss is: [[0.68652232]]\n",
            "iteration: 2114\n",
            "loss is: [[0.67550396]]\n",
            "iteration: 2115\n",
            "loss is: [[0.6609067]]\n",
            "iteration: 2116\n",
            "loss is: [[0.68107098]]\n",
            "iteration: 2117\n",
            "loss is: [[0.70883577]]\n",
            "iteration: 2118\n",
            "loss is: [[0.70934008]]\n",
            "iteration: 2119\n",
            "loss is: [[0.7028411]]\n",
            "iteration: 2120\n",
            "loss is: [[0.6794914]]\n",
            "iteration: 2121\n",
            "loss is: [[0.68164421]]\n",
            "iteration: 2122\n",
            "loss is: [[0.65758838]]\n",
            "iteration: 2123\n",
            "loss is: [[0.670094]]\n",
            "iteration: 2124\n",
            "loss is: [[0.70102077]]\n",
            "iteration: 2125\n",
            "loss is: [[0.69772133]]\n",
            "iteration: 2126\n",
            "loss is: [[0.66544272]]\n",
            "iteration: 2127\n",
            "loss is: [[0.7125542]]\n",
            "iteration: 2128\n",
            "loss is: [[0.70830415]]\n",
            "iteration: 2129\n",
            "loss is: [[0.65730157]]\n",
            "iteration: 2130\n",
            "loss is: [[0.66802018]]\n",
            "iteration: 2131\n",
            "loss is: [[0.70882208]]\n",
            "iteration: 2132\n",
            "loss is: [[0.69365743]]\n",
            "iteration: 2133\n",
            "loss is: [[0.71922477]]\n",
            "iteration: 2134\n",
            "loss is: [[0.66835867]]\n",
            "iteration: 2135\n",
            "loss is: [[0.69551165]]\n",
            "iteration: 2136\n",
            "loss is: [[0.67856768]]\n",
            "iteration: 2137\n",
            "loss is: [[0.69625792]]\n",
            "iteration: 2138\n",
            "loss is: [[0.69722242]]\n",
            "iteration: 2139\n",
            "loss is: [[0.69683449]]\n",
            "iteration: 2140\n",
            "loss is: [[0.69695546]]\n",
            "iteration: 2141\n",
            "loss is: [[0.69255679]]\n",
            "iteration: 2142\n",
            "loss is: [[0.67019817]]\n",
            "iteration: 2143\n",
            "loss is: [[0.68848312]]\n",
            "iteration: 2144\n",
            "loss is: [[0.66297996]]\n",
            "iteration: 2145\n",
            "loss is: [[0.7248127]]\n",
            "iteration: 2146\n",
            "loss is: [[0.67905838]]\n",
            "iteration: 2147\n",
            "loss is: [[0.69930312]]\n",
            "iteration: 2148\n",
            "loss is: [[0.6470035]]\n",
            "iteration: 2149\n",
            "loss is: [[0.70347059]]\n",
            "iteration: 2150\n",
            "loss is: [[0.67079156]]\n",
            "iteration: 2151\n",
            "loss is: [[0.69774676]]\n",
            "iteration: 2152\n",
            "loss is: [[0.70839054]]\n",
            "iteration: 2153\n",
            "loss is: [[0.69549435]]\n",
            "iteration: 2154\n",
            "loss is: [[0.66818623]]\n",
            "iteration: 2155\n",
            "loss is: [[0.68527501]]\n",
            "iteration: 2156\n",
            "loss is: [[0.69269567]]\n",
            "iteration: 2157\n",
            "loss is: [[0.72729282]]\n",
            "iteration: 2158\n",
            "loss is: [[0.7006841]]\n",
            "iteration: 2159\n",
            "loss is: [[0.68916118]]\n",
            "iteration: 2160\n",
            "loss is: [[0.70800102]]\n",
            "iteration: 2161\n",
            "loss is: [[0.70067549]]\n",
            "iteration: 2162\n",
            "loss is: [[0.67992754]]\n",
            "iteration: 2163\n",
            "loss is: [[0.71698333]]\n",
            "iteration: 2164\n",
            "loss is: [[0.69916156]]\n",
            "iteration: 2165\n",
            "loss is: [[0.69321217]]\n",
            "iteration: 2166\n",
            "loss is: [[0.71594944]]\n",
            "iteration: 2167\n",
            "loss is: [[0.68291224]]\n",
            "iteration: 2168\n",
            "loss is: [[0.68702637]]\n",
            "iteration: 2169\n",
            "loss is: [[0.67714669]]\n",
            "iteration: 2170\n",
            "loss is: [[0.69059449]]\n",
            "iteration: 2171\n",
            "loss is: [[0.70111425]]\n",
            "iteration: 2172\n",
            "loss is: [[0.68694733]]\n",
            "iteration: 2173\n",
            "loss is: [[0.71006963]]\n",
            "iteration: 2174\n",
            "loss is: [[0.70029656]]\n",
            "iteration: 2175\n",
            "loss is: [[0.69469064]]\n",
            "iteration: 2176\n",
            "loss is: [[0.65504956]]\n",
            "iteration: 2177\n",
            "loss is: [[0.68464985]]\n",
            "iteration: 2178\n",
            "loss is: [[0.70129619]]\n",
            "iteration: 2179\n",
            "loss is: [[0.69412936]]\n",
            "iteration: 2180\n",
            "loss is: [[0.69398468]]\n",
            "iteration: 2181\n",
            "loss is: [[0.72535374]]\n",
            "iteration: 2182\n",
            "loss is: [[0.68290116]]\n",
            "iteration: 2183\n",
            "loss is: [[0.67401239]]\n",
            "iteration: 2184\n",
            "loss is: [[0.66680927]]\n",
            "iteration: 2185\n",
            "loss is: [[0.69343832]]\n",
            "iteration: 2186\n",
            "loss is: [[0.71764132]]\n",
            "iteration: 2187\n",
            "loss is: [[0.70759032]]\n",
            "iteration: 2188\n",
            "loss is: [[0.68348509]]\n",
            "iteration: 2189\n",
            "loss is: [[0.73673749]]\n",
            "iteration: 2190\n",
            "loss is: [[0.67764398]]\n",
            "iteration: 2191\n",
            "loss is: [[0.703531]]\n",
            "iteration: 2192\n",
            "loss is: [[0.70381191]]\n",
            "iteration: 2193\n",
            "loss is: [[0.65998356]]\n",
            "iteration: 2194\n",
            "loss is: [[0.7197501]]\n",
            "iteration: 2195\n",
            "loss is: [[0.704032]]\n",
            "iteration: 2196\n",
            "loss is: [[0.70199443]]\n",
            "iteration: 2197\n",
            "loss is: [[0.69434371]]\n",
            "iteration: 2198\n",
            "loss is: [[0.6795328]]\n",
            "iteration: 2199\n",
            "loss is: [[0.68006012]]\n",
            "iteration: 2200\n",
            "loss is: [[0.68026415]]\n",
            "iteration: 2201\n",
            "loss is: [[0.70948593]]\n",
            "iteration: 2202\n",
            "loss is: [[0.6884004]]\n",
            "iteration: 2203\n",
            "loss is: [[0.68385544]]\n",
            "iteration: 2204\n",
            "loss is: [[0.68930243]]\n",
            "iteration: 2205\n",
            "loss is: [[0.66857874]]\n",
            "iteration: 2206\n",
            "loss is: [[0.69523746]]\n",
            "iteration: 2207\n",
            "loss is: [[0.71463612]]\n",
            "iteration: 2208\n",
            "loss is: [[0.67234309]]\n",
            "iteration: 2209\n",
            "loss is: [[0.6557814]]\n",
            "iteration: 2210\n",
            "loss is: [[0.65642698]]\n",
            "iteration: 2211\n",
            "loss is: [[0.67471217]]\n",
            "iteration: 2212\n",
            "loss is: [[0.70567838]]\n",
            "iteration: 2213\n",
            "loss is: [[0.72182465]]\n",
            "iteration: 2214\n",
            "loss is: [[0.71052795]]\n",
            "iteration: 2215\n",
            "loss is: [[0.6998203]]\n",
            "iteration: 2216\n",
            "loss is: [[0.69704553]]\n",
            "iteration: 2217\n",
            "loss is: [[0.69470157]]\n",
            "iteration: 2218\n",
            "loss is: [[0.70063033]]\n",
            "iteration: 2219\n",
            "loss is: [[0.67476281]]\n",
            "iteration: 2220\n",
            "loss is: [[0.69163974]]\n",
            "iteration: 2221\n",
            "loss is: [[0.68939045]]\n",
            "iteration: 2222\n",
            "loss is: [[0.67499074]]\n",
            "iteration: 2223\n",
            "loss is: [[0.63568115]]\n",
            "iteration: 2224\n",
            "loss is: [[0.7102626]]\n",
            "iteration: 2225\n",
            "loss is: [[0.67785968]]\n",
            "iteration: 2226\n",
            "loss is: [[0.68400889]]\n",
            "iteration: 2227\n",
            "loss is: [[0.670493]]\n",
            "iteration: 2228\n",
            "loss is: [[0.66786054]]\n",
            "iteration: 2229\n",
            "loss is: [[0.69819083]]\n",
            "iteration: 2230\n",
            "loss is: [[0.68678955]]\n",
            "iteration: 2231\n",
            "loss is: [[0.69312898]]\n",
            "iteration: 2232\n",
            "loss is: [[0.67239851]]\n",
            "iteration: 2233\n",
            "loss is: [[0.68669189]]\n",
            "iteration: 2234\n",
            "loss is: [[0.68116681]]\n",
            "iteration: 2235\n",
            "loss is: [[0.71187616]]\n",
            "iteration: 2236\n",
            "loss is: [[0.68238151]]\n",
            "iteration: 2237\n",
            "loss is: [[0.69429769]]\n",
            "iteration: 2238\n",
            "loss is: [[0.6949797]]\n",
            "iteration: 2239\n",
            "loss is: [[0.67532967]]\n",
            "iteration: 2240\n",
            "loss is: [[0.69469368]]\n",
            "iteration: 2241\n",
            "loss is: [[0.67962944]]\n",
            "iteration: 2242\n",
            "loss is: [[0.69417612]]\n",
            "iteration: 2243\n",
            "loss is: [[0.66042504]]\n",
            "iteration: 2244\n",
            "loss is: [[0.68570782]]\n",
            "iteration: 2245\n",
            "loss is: [[0.67851868]]\n",
            "iteration: 2246\n",
            "loss is: [[0.65236146]]\n",
            "iteration: 2247\n",
            "loss is: [[0.66789686]]\n",
            "iteration: 2248\n",
            "loss is: [[0.66250777]]\n",
            "iteration: 2249\n",
            "loss is: [[0.69389719]]\n",
            "iteration: 2250\n",
            "loss is: [[0.68243027]]\n",
            "iteration: 2251\n",
            "loss is: [[0.67898673]]\n",
            "iteration: 2252\n",
            "loss is: [[0.71912414]]\n",
            "iteration: 2253\n",
            "loss is: [[0.71602268]]\n",
            "iteration: 2254\n",
            "loss is: [[0.67694638]]\n",
            "iteration: 2255\n",
            "loss is: [[0.66418567]]\n",
            "iteration: 2256\n",
            "loss is: [[0.70571068]]\n",
            "iteration: 2257\n",
            "loss is: [[0.69147201]]\n",
            "iteration: 2258\n",
            "loss is: [[0.7094381]]\n",
            "iteration: 2259\n",
            "loss is: [[0.69812552]]\n",
            "iteration: 2260\n",
            "loss is: [[0.60965718]]\n",
            "iteration: 2261\n",
            "loss is: [[0.68722342]]\n",
            "iteration: 2262\n",
            "loss is: [[0.68368828]]\n",
            "iteration: 2263\n",
            "loss is: [[0.68957998]]\n",
            "iteration: 2264\n",
            "loss is: [[0.7199709]]\n",
            "iteration: 2265\n",
            "loss is: [[0.67382948]]\n",
            "iteration: 2266\n",
            "loss is: [[0.64913489]]\n",
            "iteration: 2267\n",
            "loss is: [[0.72949344]]\n",
            "iteration: 2268\n",
            "loss is: [[0.72090681]]\n",
            "iteration: 2269\n",
            "loss is: [[0.71949886]]\n",
            "iteration: 2270\n",
            "loss is: [[0.7221316]]\n",
            "iteration: 2271\n",
            "loss is: [[0.71260837]]\n",
            "iteration: 2272\n",
            "loss is: [[0.72270544]]\n",
            "iteration: 2273\n",
            "loss is: [[0.68239189]]\n",
            "iteration: 2274\n",
            "loss is: [[0.70491261]]\n",
            "iteration: 2275\n",
            "loss is: [[0.7195254]]\n",
            "iteration: 2276\n",
            "loss is: [[0.68956108]]\n",
            "iteration: 2277\n",
            "loss is: [[0.64944353]]\n",
            "iteration: 2278\n",
            "loss is: [[0.68021637]]\n",
            "iteration: 2279\n",
            "loss is: [[0.67303734]]\n",
            "iteration: 2280\n",
            "loss is: [[0.71372313]]\n",
            "iteration: 2281\n",
            "loss is: [[0.68653312]]\n",
            "iteration: 2282\n",
            "loss is: [[0.67266524]]\n",
            "iteration: 2283\n",
            "loss is: [[0.67364753]]\n",
            "iteration: 2284\n",
            "loss is: [[0.67606457]]\n",
            "iteration: 2285\n",
            "loss is: [[0.66861583]]\n",
            "iteration: 2286\n",
            "loss is: [[0.64777439]]\n",
            "iteration: 2287\n",
            "loss is: [[0.63954836]]\n",
            "iteration: 2288\n",
            "loss is: [[0.70736023]]\n",
            "iteration: 2289\n",
            "loss is: [[0.6828331]]\n",
            "iteration: 2290\n",
            "loss is: [[0.66136045]]\n",
            "iteration: 2291\n",
            "loss is: [[0.71380006]]\n",
            "iteration: 2292\n",
            "loss is: [[0.67039027]]\n",
            "iteration: 2293\n",
            "loss is: [[0.64750405]]\n",
            "iteration: 2294\n",
            "loss is: [[0.66722309]]\n",
            "iteration: 2295\n",
            "loss is: [[0.68796048]]\n",
            "iteration: 2296\n",
            "loss is: [[0.67416296]]\n",
            "iteration: 2297\n",
            "loss is: [[0.69225818]]\n",
            "iteration: 2298\n",
            "loss is: [[0.65432438]]\n",
            "iteration: 2299\n",
            "loss is: [[0.67942633]]\n",
            "iteration: 2300\n",
            "loss is: [[0.70218188]]\n",
            "iteration: 2301\n",
            "loss is: [[0.69686888]]\n",
            "iteration: 2302\n",
            "loss is: [[0.71976989]]\n",
            "iteration: 2303\n",
            "loss is: [[0.69509082]]\n",
            "iteration: 2304\n",
            "loss is: [[0.68841043]]\n",
            "iteration: 2305\n",
            "loss is: [[0.67063861]]\n",
            "iteration: 2306\n",
            "loss is: [[0.70618934]]\n",
            "iteration: 2307\n",
            "loss is: [[0.6795443]]\n",
            "iteration: 2308\n",
            "loss is: [[0.68092635]]\n",
            "iteration: 2309\n",
            "loss is: [[0.65244411]]\n",
            "iteration: 2310\n",
            "loss is: [[0.67221221]]\n",
            "iteration: 2311\n",
            "loss is: [[0.69477073]]\n",
            "iteration: 2312\n",
            "loss is: [[0.71212775]]\n",
            "iteration: 2313\n",
            "loss is: [[0.68990326]]\n",
            "iteration: 2314\n",
            "loss is: [[0.67898884]]\n",
            "iteration: 2315\n",
            "loss is: [[0.70540476]]\n",
            "iteration: 2316\n",
            "loss is: [[0.68359921]]\n",
            "iteration: 2317\n",
            "loss is: [[0.6711133]]\n",
            "iteration: 2318\n",
            "loss is: [[0.66588787]]\n",
            "iteration: 2319\n",
            "loss is: [[0.70847777]]\n",
            "iteration: 2320\n",
            "loss is: [[0.69156761]]\n",
            "iteration: 2321\n",
            "loss is: [[0.68121841]]\n",
            "iteration: 2322\n",
            "loss is: [[0.6762495]]\n",
            "iteration: 2323\n",
            "loss is: [[0.70111755]]\n",
            "iteration: 2324\n",
            "loss is: [[0.73140681]]\n",
            "iteration: 2325\n",
            "loss is: [[0.69057209]]\n",
            "iteration: 2326\n",
            "loss is: [[0.685346]]\n",
            "iteration: 2327\n",
            "loss is: [[0.67052041]]\n",
            "iteration: 2328\n",
            "loss is: [[0.70371942]]\n",
            "iteration: 2329\n",
            "loss is: [[0.69518327]]\n",
            "iteration: 2330\n",
            "loss is: [[0.66318167]]\n",
            "iteration: 2331\n",
            "loss is: [[0.66756247]]\n",
            "iteration: 2332\n",
            "loss is: [[0.65990326]]\n",
            "iteration: 2333\n",
            "loss is: [[0.68563381]]\n",
            "iteration: 2334\n",
            "loss is: [[0.71594215]]\n",
            "iteration: 2335\n",
            "loss is: [[0.64855325]]\n",
            "iteration: 2336\n",
            "loss is: [[0.71082424]]\n",
            "iteration: 2337\n",
            "loss is: [[0.65711255]]\n",
            "iteration: 2338\n",
            "loss is: [[0.69708395]]\n",
            "iteration: 2339\n",
            "loss is: [[0.65456328]]\n",
            "iteration: 2340\n",
            "loss is: [[0.64983701]]\n",
            "iteration: 2341\n",
            "loss is: [[0.70493215]]\n",
            "iteration: 2342\n",
            "loss is: [[0.69368134]]\n",
            "iteration: 2343\n",
            "loss is: [[0.69357253]]\n",
            "iteration: 2344\n",
            "loss is: [[0.7379239]]\n",
            "iteration: 2345\n",
            "loss is: [[0.69564448]]\n",
            "iteration: 2346\n",
            "loss is: [[0.70153786]]\n",
            "iteration: 2347\n",
            "loss is: [[0.67820803]]\n",
            "iteration: 2348\n",
            "loss is: [[0.66898423]]\n",
            "iteration: 2349\n",
            "loss is: [[0.68494694]]\n",
            "iteration: 2350\n",
            "loss is: [[0.70885758]]\n",
            "iteration: 2351\n",
            "loss is: [[0.64839484]]\n",
            "iteration: 2352\n",
            "loss is: [[0.68555387]]\n",
            "iteration: 2353\n",
            "loss is: [[0.70997673]]\n",
            "iteration: 2354\n",
            "loss is: [[0.69688417]]\n",
            "iteration: 2355\n",
            "loss is: [[0.68269895]]\n",
            "iteration: 2356\n",
            "loss is: [[0.68083016]]\n",
            "iteration: 2357\n",
            "loss is: [[0.70192634]]\n",
            "iteration: 2358\n",
            "loss is: [[0.66478969]]\n",
            "iteration: 2359\n",
            "loss is: [[0.68243484]]\n",
            "iteration: 2360\n",
            "loss is: [[0.70636592]]\n",
            "iteration: 2361\n",
            "loss is: [[0.70715485]]\n",
            "iteration: 2362\n",
            "loss is: [[0.67408133]]\n",
            "iteration: 2363\n",
            "loss is: [[0.6840006]]\n",
            "iteration: 2364\n",
            "loss is: [[0.69457919]]\n",
            "iteration: 2365\n",
            "loss is: [[0.67623614]]\n",
            "iteration: 2366\n",
            "loss is: [[0.71571481]]\n",
            "iteration: 2367\n",
            "loss is: [[0.69094812]]\n",
            "iteration: 2368\n",
            "loss is: [[0.67290207]]\n",
            "iteration: 2369\n",
            "loss is: [[0.69585975]]\n",
            "iteration: 2370\n",
            "loss is: [[0.67215727]]\n",
            "iteration: 2371\n",
            "loss is: [[0.69105368]]\n",
            "iteration: 2372\n",
            "loss is: [[0.69957219]]\n",
            "iteration: 2373\n",
            "loss is: [[0.72257245]]\n",
            "iteration: 2374\n",
            "loss is: [[0.7176475]]\n",
            "iteration: 2375\n",
            "loss is: [[0.70344221]]\n",
            "iteration: 2376\n",
            "loss is: [[0.6856748]]\n",
            "iteration: 2377\n",
            "loss is: [[0.68541]]\n",
            "iteration: 2378\n",
            "loss is: [[0.68791774]]\n",
            "iteration: 2379\n",
            "loss is: [[0.68537949]]\n",
            "iteration: 2380\n",
            "loss is: [[0.6882979]]\n",
            "iteration: 2381\n",
            "loss is: [[0.68823281]]\n",
            "iteration: 2382\n",
            "loss is: [[0.66177333]]\n",
            "iteration: 2383\n",
            "loss is: [[0.69198729]]\n",
            "iteration: 2384\n",
            "loss is: [[0.67217873]]\n",
            "iteration: 2385\n",
            "loss is: [[0.65656571]]\n",
            "iteration: 2386\n",
            "loss is: [[0.67759023]]\n",
            "iteration: 2387\n",
            "loss is: [[0.64639613]]\n",
            "iteration: 2388\n",
            "loss is: [[0.62451786]]\n",
            "iteration: 2389\n",
            "loss is: [[0.68736377]]\n",
            "iteration: 2390\n",
            "loss is: [[0.69556328]]\n",
            "iteration: 2391\n",
            "loss is: [[0.6975135]]\n",
            "iteration: 2392\n",
            "loss is: [[0.68979253]]\n",
            "iteration: 2393\n",
            "loss is: [[0.71792085]]\n",
            "iteration: 2394\n",
            "loss is: [[0.67300635]]\n",
            "iteration: 2395\n",
            "loss is: [[0.66846503]]\n",
            "iteration: 2396\n",
            "loss is: [[0.63381732]]\n",
            "iteration: 2397\n",
            "loss is: [[0.67729579]]\n",
            "iteration: 2398\n",
            "loss is: [[0.70662692]]\n",
            "iteration: 2399\n",
            "loss is: [[0.68892069]]\n",
            "iteration: 2400\n",
            "loss is: [[0.66829679]]\n",
            "iteration: 2401\n",
            "loss is: [[0.66117655]]\n",
            "iteration: 2402\n",
            "loss is: [[0.67465532]]\n",
            "iteration: 2403\n",
            "loss is: [[0.68747505]]\n",
            "iteration: 2404\n",
            "loss is: [[0.66564248]]\n",
            "iteration: 2405\n",
            "loss is: [[0.66057104]]\n",
            "iteration: 2406\n",
            "loss is: [[0.68185738]]\n",
            "iteration: 2407\n",
            "loss is: [[0.65597818]]\n",
            "iteration: 2408\n",
            "loss is: [[0.68018986]]\n",
            "iteration: 2409\n",
            "loss is: [[0.69878549]]\n",
            "iteration: 2410\n",
            "loss is: [[0.66698062]]\n",
            "iteration: 2411\n",
            "loss is: [[0.70579542]]\n",
            "iteration: 2412\n",
            "loss is: [[0.69202761]]\n",
            "iteration: 2413\n",
            "loss is: [[0.68985307]]\n",
            "iteration: 2414\n",
            "loss is: [[0.71810692]]\n",
            "iteration: 2415\n",
            "loss is: [[0.68196989]]\n",
            "iteration: 2416\n",
            "loss is: [[0.71915609]]\n",
            "iteration: 2417\n",
            "loss is: [[0.70586845]]\n",
            "iteration: 2418\n",
            "loss is: [[0.68008343]]\n",
            "iteration: 2419\n",
            "loss is: [[0.69889067]]\n",
            "iteration: 2420\n",
            "loss is: [[0.67823285]]\n",
            "iteration: 2421\n",
            "loss is: [[0.70588716]]\n",
            "iteration: 2422\n",
            "loss is: [[0.64502129]]\n",
            "iteration: 2423\n",
            "loss is: [[0.65998503]]\n",
            "iteration: 2424\n",
            "loss is: [[0.67434806]]\n",
            "iteration: 2425\n",
            "loss is: [[0.68235757]]\n",
            "iteration: 2426\n",
            "loss is: [[0.64722904]]\n",
            "iteration: 2427\n",
            "loss is: [[0.72580686]]\n",
            "iteration: 2428\n",
            "loss is: [[0.66895971]]\n",
            "iteration: 2429\n",
            "loss is: [[0.67521709]]\n",
            "iteration: 2430\n",
            "loss is: [[0.69305198]]\n",
            "iteration: 2431\n",
            "loss is: [[0.69281859]]\n",
            "iteration: 2432\n",
            "loss is: [[0.66980603]]\n",
            "iteration: 2433\n",
            "loss is: [[0.69772408]]\n",
            "iteration: 2434\n",
            "loss is: [[0.67460372]]\n",
            "iteration: 2435\n",
            "loss is: [[0.71169615]]\n",
            "iteration: 2436\n",
            "loss is: [[0.70823908]]\n",
            "iteration: 2437\n",
            "loss is: [[0.69069881]]\n",
            "iteration: 2438\n",
            "loss is: [[0.67844716]]\n",
            "iteration: 2439\n",
            "loss is: [[0.68071622]]\n",
            "iteration: 2440\n",
            "loss is: [[0.71100253]]\n",
            "iteration: 2441\n",
            "loss is: [[0.72882919]]\n",
            "iteration: 2442\n",
            "loss is: [[0.6702724]]\n",
            "iteration: 2443\n",
            "loss is: [[0.67417855]]\n",
            "iteration: 2444\n",
            "loss is: [[0.68842002]]\n",
            "iteration: 2445\n",
            "loss is: [[0.68642719]]\n",
            "iteration: 2446\n",
            "loss is: [[0.67401361]]\n",
            "iteration: 2447\n",
            "loss is: [[0.69132554]]\n",
            "iteration: 2448\n",
            "loss is: [[0.71646883]]\n",
            "iteration: 2449\n",
            "loss is: [[0.67234505]]\n",
            "iteration: 2450\n",
            "loss is: [[0.62874104]]\n",
            "iteration: 2451\n",
            "loss is: [[0.66869204]]\n",
            "iteration: 2452\n",
            "loss is: [[0.63345509]]\n",
            "iteration: 2453\n",
            "loss is: [[0.68811072]]\n",
            "iteration: 2454\n",
            "loss is: [[0.68539905]]\n",
            "iteration: 2455\n",
            "loss is: [[0.68035409]]\n",
            "iteration: 2456\n",
            "loss is: [[0.67634167]]\n",
            "iteration: 2457\n",
            "loss is: [[0.64501672]]\n",
            "iteration: 2458\n",
            "loss is: [[0.67596794]]\n",
            "iteration: 2459\n",
            "loss is: [[0.67958931]]\n",
            "iteration: 2460\n",
            "loss is: [[0.66902959]]\n",
            "iteration: 2461\n",
            "loss is: [[0.66708228]]\n",
            "iteration: 2462\n",
            "loss is: [[0.71029918]]\n",
            "iteration: 2463\n",
            "loss is: [[0.67937448]]\n",
            "iteration: 2464\n",
            "loss is: [[0.7223167]]\n",
            "iteration: 2465\n",
            "loss is: [[0.65956003]]\n",
            "iteration: 2466\n",
            "loss is: [[0.64704924]]\n",
            "iteration: 2467\n",
            "loss is: [[0.65860016]]\n",
            "iteration: 2468\n",
            "loss is: [[0.6859473]]\n",
            "iteration: 2469\n",
            "loss is: [[0.67942923]]\n",
            "iteration: 2470\n",
            "loss is: [[0.67834358]]\n",
            "iteration: 2471\n",
            "loss is: [[0.68274743]]\n",
            "iteration: 2472\n",
            "loss is: [[0.67090401]]\n",
            "iteration: 2473\n",
            "loss is: [[0.70751623]]\n",
            "iteration: 2474\n",
            "loss is: [[0.64246232]]\n",
            "iteration: 2475\n",
            "loss is: [[0.68678143]]\n",
            "iteration: 2476\n",
            "loss is: [[0.65561736]]\n",
            "iteration: 2477\n",
            "loss is: [[0.67209157]]\n",
            "iteration: 2478\n",
            "loss is: [[0.67260728]]\n",
            "iteration: 2479\n",
            "loss is: [[0.66274005]]\n",
            "iteration: 2480\n",
            "loss is: [[0.67697728]]\n",
            "iteration: 2481\n",
            "loss is: [[0.70512914]]\n",
            "iteration: 2482\n",
            "loss is: [[0.68237733]]\n",
            "iteration: 2483\n",
            "loss is: [[0.70188723]]\n",
            "iteration: 2484\n",
            "loss is: [[0.67609874]]\n",
            "iteration: 2485\n",
            "loss is: [[0.67483857]]\n",
            "iteration: 2486\n",
            "loss is: [[0.66195166]]\n",
            "iteration: 2487\n",
            "loss is: [[0.70580907]]\n",
            "iteration: 2488\n",
            "loss is: [[0.69615948]]\n",
            "iteration: 2489\n",
            "loss is: [[0.67229334]]\n",
            "iteration: 2490\n",
            "loss is: [[0.68690759]]\n",
            "iteration: 2491\n",
            "loss is: [[0.676321]]\n",
            "iteration: 2492\n",
            "loss is: [[0.6721373]]\n",
            "iteration: 2493\n",
            "loss is: [[0.69070547]]\n",
            "iteration: 2494\n",
            "loss is: [[0.70654839]]\n",
            "iteration: 2495\n",
            "loss is: [[0.70050924]]\n",
            "iteration: 2496\n",
            "loss is: [[0.6587583]]\n",
            "iteration: 2497\n",
            "loss is: [[0.67218719]]\n",
            "iteration: 2498\n",
            "loss is: [[0.6343239]]\n",
            "iteration: 2499\n",
            "loss is: [[0.72667638]]\n",
            "iteration: 2500\n",
            "loss is: [[0.69993563]]\n",
            "iteration: 2501\n",
            "loss is: [[0.71685477]]\n",
            "iteration: 2502\n",
            "loss is: [[0.68926845]]\n",
            "iteration: 2503\n",
            "loss is: [[0.67197698]]\n",
            "iteration: 2504\n",
            "loss is: [[0.72099118]]\n",
            "iteration: 2505\n",
            "loss is: [[0.67770301]]\n",
            "iteration: 2506\n",
            "loss is: [[0.65200691]]\n",
            "iteration: 2507\n",
            "loss is: [[0.69214437]]\n",
            "iteration: 2508\n",
            "loss is: [[0.7036415]]\n",
            "iteration: 2509\n",
            "loss is: [[0.69670327]]\n",
            "iteration: 2510\n",
            "loss is: [[0.74007084]]\n",
            "iteration: 2511\n",
            "loss is: [[0.69491194]]\n",
            "iteration: 2512\n",
            "loss is: [[0.68595006]]\n",
            "iteration: 2513\n",
            "loss is: [[0.6760853]]\n",
            "iteration: 2514\n",
            "loss is: [[0.69855503]]\n",
            "iteration: 2515\n",
            "loss is: [[0.68786716]]\n",
            "iteration: 2516\n",
            "loss is: [[0.70980903]]\n",
            "iteration: 2517\n",
            "loss is: [[0.68231456]]\n",
            "iteration: 2518\n",
            "loss is: [[0.67341322]]\n",
            "iteration: 2519\n",
            "loss is: [[0.69211419]]\n",
            "iteration: 2520\n",
            "loss is: [[0.68301885]]\n",
            "iteration: 2521\n",
            "loss is: [[0.68120049]]\n",
            "iteration: 2522\n",
            "loss is: [[0.70157207]]\n",
            "iteration: 2523\n",
            "loss is: [[0.73566507]]\n",
            "iteration: 2524\n",
            "loss is: [[0.69108676]]\n",
            "iteration: 2525\n",
            "loss is: [[0.70155924]]\n",
            "iteration: 2526\n",
            "loss is: [[0.68757126]]\n",
            "iteration: 2527\n",
            "loss is: [[0.68931686]]\n",
            "iteration: 2528\n",
            "loss is: [[0.697476]]\n",
            "iteration: 2529\n",
            "loss is: [[0.69159252]]\n",
            "iteration: 2530\n",
            "loss is: [[0.70788398]]\n",
            "iteration: 2531\n",
            "loss is: [[0.71330771]]\n",
            "iteration: 2532\n",
            "loss is: [[0.67959389]]\n",
            "iteration: 2533\n",
            "loss is: [[0.71101411]]\n",
            "iteration: 2534\n",
            "loss is: [[0.66434267]]\n",
            "iteration: 2535\n",
            "loss is: [[0.69256753]]\n",
            "iteration: 2536\n",
            "loss is: [[0.65824171]]\n",
            "iteration: 2537\n",
            "loss is: [[0.68713431]]\n",
            "iteration: 2538\n",
            "loss is: [[0.66596962]]\n",
            "iteration: 2539\n",
            "loss is: [[0.66776201]]\n",
            "iteration: 2540\n",
            "loss is: [[0.66390027]]\n",
            "iteration: 2541\n",
            "loss is: [[0.69564837]]\n",
            "iteration: 2542\n",
            "loss is: [[0.68872422]]\n",
            "iteration: 2543\n",
            "loss is: [[0.69387849]]\n",
            "iteration: 2544\n",
            "loss is: [[0.673866]]\n",
            "iteration: 2545\n",
            "loss is: [[0.69481301]]\n",
            "iteration: 2546\n",
            "loss is: [[0.69795985]]\n",
            "iteration: 2547\n",
            "loss is: [[0.65926306]]\n",
            "iteration: 2548\n",
            "loss is: [[0.6836067]]\n",
            "iteration: 2549\n",
            "loss is: [[0.68616386]]\n",
            "iteration: 2550\n",
            "loss is: [[0.68106534]]\n",
            "iteration: 2551\n",
            "loss is: [[0.68019646]]\n",
            "iteration: 2552\n",
            "loss is: [[0.67397935]]\n",
            "iteration: 2553\n",
            "loss is: [[0.67518506]]\n",
            "iteration: 2554\n",
            "loss is: [[0.68372562]]\n",
            "iteration: 2555\n",
            "loss is: [[0.65829141]]\n",
            "iteration: 2556\n",
            "loss is: [[0.69578616]]\n",
            "iteration: 2557\n",
            "loss is: [[0.68827407]]\n",
            "iteration: 2558\n",
            "loss is: [[0.6600568]]\n",
            "iteration: 2559\n",
            "loss is: [[0.68861551]]\n",
            "iteration: 2560\n",
            "loss is: [[0.66486439]]\n",
            "iteration: 2561\n",
            "loss is: [[0.68422053]]\n",
            "iteration: 2562\n",
            "loss is: [[0.68195527]]\n",
            "iteration: 2563\n",
            "loss is: [[0.69124816]]\n",
            "iteration: 2564\n",
            "loss is: [[0.69076858]]\n",
            "iteration: 2565\n",
            "loss is: [[0.68762808]]\n",
            "iteration: 2566\n",
            "loss is: [[0.71668209]]\n",
            "iteration: 2567\n",
            "loss is: [[0.70427008]]\n",
            "iteration: 2568\n",
            "loss is: [[0.67085739]]\n",
            "iteration: 2569\n",
            "loss is: [[0.66700098]]\n",
            "iteration: 2570\n",
            "loss is: [[0.66850869]]\n",
            "iteration: 2571\n",
            "loss is: [[0.68587171]]\n",
            "iteration: 2572\n",
            "loss is: [[0.69219411]]\n",
            "iteration: 2573\n",
            "loss is: [[0.6954549]]\n",
            "iteration: 2574\n",
            "loss is: [[0.70182298]]\n",
            "iteration: 2575\n",
            "loss is: [[0.67489098]]\n",
            "iteration: 2576\n",
            "loss is: [[0.68921891]]\n",
            "iteration: 2577\n",
            "loss is: [[0.68979055]]\n",
            "iteration: 2578\n",
            "loss is: [[0.69929598]]\n",
            "iteration: 2579\n",
            "loss is: [[0.67185306]]\n",
            "iteration: 2580\n",
            "loss is: [[0.69469433]]\n",
            "iteration: 2581\n",
            "loss is: [[0.69604678]]\n",
            "iteration: 2582\n",
            "loss is: [[0.67186111]]\n",
            "iteration: 2583\n",
            "loss is: [[0.661535]]\n",
            "iteration: 2584\n",
            "loss is: [[0.70473726]]\n",
            "iteration: 2585\n",
            "loss is: [[0.7119671]]\n",
            "iteration: 2586\n",
            "loss is: [[0.70338276]]\n",
            "iteration: 2587\n",
            "loss is: [[0.66500092]]\n",
            "iteration: 2588\n",
            "loss is: [[0.69392288]]\n",
            "iteration: 2589\n",
            "loss is: [[0.67175932]]\n",
            "iteration: 2590\n",
            "loss is: [[0.68171879]]\n",
            "iteration: 2591\n",
            "loss is: [[0.72216214]]\n",
            "iteration: 2592\n",
            "loss is: [[0.67924709]]\n",
            "iteration: 2593\n",
            "loss is: [[0.69219743]]\n",
            "iteration: 2594\n",
            "loss is: [[0.68499961]]\n",
            "iteration: 2595\n",
            "loss is: [[0.66414232]]\n",
            "iteration: 2596\n",
            "loss is: [[0.67199982]]\n",
            "iteration: 2597\n",
            "loss is: [[0.7138768]]\n",
            "iteration: 2598\n",
            "loss is: [[0.68520049]]\n",
            "iteration: 2599\n",
            "loss is: [[0.72232053]]\n",
            "iteration: 2600\n",
            "loss is: [[0.64870617]]\n",
            "iteration: 2601\n",
            "loss is: [[0.69150731]]\n",
            "iteration: 2602\n",
            "loss is: [[0.68586966]]\n",
            "iteration: 2603\n",
            "loss is: [[0.7246245]]\n",
            "iteration: 2604\n",
            "loss is: [[0.65237642]]\n",
            "iteration: 2605\n",
            "loss is: [[0.67902111]]\n",
            "iteration: 2606\n",
            "loss is: [[0.68655044]]\n",
            "iteration: 2607\n",
            "loss is: [[0.6929975]]\n",
            "iteration: 2608\n",
            "loss is: [[0.69381515]]\n",
            "iteration: 2609\n",
            "loss is: [[0.66899368]]\n",
            "iteration: 2610\n",
            "loss is: [[0.69843823]]\n",
            "iteration: 2611\n",
            "loss is: [[0.69940496]]\n",
            "iteration: 2612\n",
            "loss is: [[0.67896805]]\n",
            "iteration: 2613\n",
            "loss is: [[0.68752952]]\n",
            "iteration: 2614\n",
            "loss is: [[0.68832643]]\n",
            "iteration: 2615\n",
            "loss is: [[0.69010083]]\n",
            "iteration: 2616\n",
            "loss is: [[0.65168417]]\n",
            "iteration: 2617\n",
            "loss is: [[0.67903124]]\n",
            "iteration: 2618\n",
            "loss is: [[0.68324104]]\n",
            "iteration: 2619\n",
            "loss is: [[0.68071475]]\n",
            "iteration: 2620\n",
            "loss is: [[0.66573365]]\n",
            "iteration: 2621\n",
            "loss is: [[0.6819651]]\n",
            "iteration: 2622\n",
            "loss is: [[0.67572461]]\n",
            "iteration: 2623\n",
            "loss is: [[0.67371077]]\n",
            "iteration: 2624\n",
            "loss is: [[0.67879467]]\n",
            "iteration: 2625\n",
            "loss is: [[0.70411745]]\n",
            "iteration: 2626\n",
            "loss is: [[0.70971361]]\n",
            "iteration: 2627\n",
            "loss is: [[0.69707721]]\n",
            "iteration: 2628\n",
            "loss is: [[0.70641388]]\n",
            "iteration: 2629\n",
            "loss is: [[0.70125475]]\n",
            "iteration: 2630\n",
            "loss is: [[0.68997394]]\n",
            "iteration: 2631\n",
            "loss is: [[0.66743487]]\n",
            "iteration: 2632\n",
            "loss is: [[0.67611588]]\n",
            "iteration: 2633\n",
            "loss is: [[0.68293639]]\n",
            "iteration: 2634\n",
            "loss is: [[0.68978354]]\n",
            "iteration: 2635\n",
            "loss is: [[0.72388938]]\n",
            "iteration: 2636\n",
            "loss is: [[0.66935795]]\n",
            "iteration: 2637\n",
            "loss is: [[0.66491425]]\n",
            "iteration: 2638\n",
            "loss is: [[0.67931932]]\n",
            "iteration: 2639\n",
            "loss is: [[0.70055963]]\n",
            "iteration: 2640\n",
            "loss is: [[0.66431919]]\n",
            "iteration: 2641\n",
            "loss is: [[0.72815292]]\n",
            "iteration: 2642\n",
            "loss is: [[0.69502613]]\n",
            "iteration: 2643\n",
            "loss is: [[0.69852199]]\n",
            "iteration: 2644\n",
            "loss is: [[0.62915795]]\n",
            "iteration: 2645\n",
            "loss is: [[0.68225132]]\n",
            "iteration: 2646\n",
            "loss is: [[0.67544321]]\n",
            "iteration: 2647\n",
            "loss is: [[0.73265193]]\n",
            "iteration: 2648\n",
            "loss is: [[0.6744082]]\n",
            "iteration: 2649\n",
            "loss is: [[0.6923558]]\n",
            "iteration: 2650\n",
            "loss is: [[0.68393941]]\n",
            "iteration: 2651\n",
            "loss is: [[0.69414822]]\n",
            "iteration: 2652\n",
            "loss is: [[0.67578937]]\n",
            "iteration: 2653\n",
            "loss is: [[0.67844734]]\n",
            "iteration: 2654\n",
            "loss is: [[0.6564163]]\n",
            "iteration: 2655\n",
            "loss is: [[0.69938312]]\n",
            "iteration: 2656\n",
            "loss is: [[0.69314847]]\n",
            "iteration: 2657\n",
            "loss is: [[0.69324195]]\n",
            "iteration: 2658\n",
            "loss is: [[0.63412915]]\n",
            "iteration: 2659\n",
            "loss is: [[0.70855839]]\n",
            "iteration: 2660\n",
            "loss is: [[0.67296055]]\n",
            "iteration: 2661\n",
            "loss is: [[0.67989866]]\n",
            "iteration: 2662\n",
            "loss is: [[0.69119017]]\n",
            "iteration: 2663\n",
            "loss is: [[0.69775374]]\n",
            "iteration: 2664\n",
            "loss is: [[0.69467645]]\n",
            "iteration: 2665\n",
            "loss is: [[0.70259747]]\n",
            "iteration: 2666\n",
            "loss is: [[0.69671405]]\n",
            "iteration: 2667\n",
            "loss is: [[0.69974782]]\n",
            "iteration: 2668\n",
            "loss is: [[0.69827418]]\n",
            "iteration: 2669\n",
            "loss is: [[0.71307784]]\n",
            "iteration: 2670\n",
            "loss is: [[0.67421336]]\n",
            "iteration: 2671\n",
            "loss is: [[0.72740216]]\n",
            "iteration: 2672\n",
            "loss is: [[0.66187277]]\n",
            "iteration: 2673\n",
            "loss is: [[0.66812376]]\n",
            "iteration: 2674\n",
            "loss is: [[0.6928651]]\n",
            "iteration: 2675\n",
            "loss is: [[0.68188238]]\n",
            "iteration: 2676\n",
            "loss is: [[0.70298695]]\n",
            "iteration: 2677\n",
            "loss is: [[0.68205979]]\n",
            "iteration: 2678\n",
            "loss is: [[0.69943754]]\n",
            "iteration: 2679\n",
            "loss is: [[0.67778942]]\n",
            "iteration: 2680\n",
            "loss is: [[0.68826444]]\n",
            "iteration: 2681\n",
            "loss is: [[0.67112778]]\n",
            "iteration: 2682\n",
            "loss is: [[0.67216365]]\n",
            "iteration: 2683\n",
            "loss is: [[0.69891632]]\n",
            "iteration: 2684\n",
            "loss is: [[0.69709466]]\n",
            "iteration: 2685\n",
            "loss is: [[0.67748193]]\n",
            "iteration: 2686\n",
            "loss is: [[0.6508527]]\n",
            "iteration: 2687\n",
            "loss is: [[0.716063]]\n",
            "iteration: 2688\n",
            "loss is: [[0.68150498]]\n",
            "iteration: 2689\n",
            "loss is: [[0.70897834]]\n",
            "iteration: 2690\n",
            "loss is: [[0.68239611]]\n",
            "iteration: 2691\n",
            "loss is: [[0.64271076]]\n",
            "iteration: 2692\n",
            "loss is: [[0.70956829]]\n",
            "iteration: 2693\n",
            "loss is: [[0.65731727]]\n",
            "iteration: 2694\n",
            "loss is: [[0.67370887]]\n",
            "iteration: 2695\n",
            "loss is: [[0.70037914]]\n",
            "iteration: 2696\n",
            "loss is: [[0.68775732]]\n",
            "iteration: 2697\n",
            "loss is: [[0.69836306]]\n",
            "iteration: 2698\n",
            "loss is: [[0.70993862]]\n",
            "iteration: 2699\n",
            "loss is: [[0.6951873]]\n",
            "iteration: 2700\n",
            "loss is: [[0.68222424]]\n",
            "iteration: 2701\n",
            "loss is: [[0.67623732]]\n",
            "iteration: 2702\n",
            "loss is: [[0.67261657]]\n",
            "iteration: 2703\n",
            "loss is: [[0.68083167]]\n",
            "iteration: 2704\n",
            "loss is: [[0.70816837]]\n",
            "iteration: 2705\n",
            "loss is: [[0.64726663]]\n",
            "iteration: 2706\n",
            "loss is: [[0.68461051]]\n",
            "iteration: 2707\n",
            "loss is: [[0.67572956]]\n",
            "iteration: 2708\n",
            "loss is: [[0.70895806]]\n",
            "iteration: 2709\n",
            "loss is: [[0.74427149]]\n",
            "iteration: 2710\n",
            "loss is: [[0.67397591]]\n",
            "iteration: 2711\n",
            "loss is: [[0.67733654]]\n",
            "iteration: 2712\n",
            "loss is: [[0.69776179]]\n",
            "iteration: 2713\n",
            "loss is: [[0.69938139]]\n",
            "iteration: 2714\n",
            "loss is: [[0.68843865]]\n",
            "iteration: 2715\n",
            "loss is: [[0.67477401]]\n",
            "iteration: 2716\n",
            "loss is: [[0.67552867]]\n",
            "iteration: 2717\n",
            "loss is: [[0.67811123]]\n",
            "iteration: 2718\n",
            "loss is: [[0.67330577]]\n",
            "iteration: 2719\n",
            "loss is: [[0.68467294]]\n",
            "iteration: 2720\n",
            "loss is: [[0.69317363]]\n",
            "iteration: 2721\n",
            "loss is: [[0.64227088]]\n",
            "iteration: 2722\n",
            "loss is: [[0.7095631]]\n",
            "iteration: 2723\n",
            "loss is: [[0.71663033]]\n",
            "iteration: 2724\n",
            "loss is: [[0.71342257]]\n",
            "iteration: 2725\n",
            "loss is: [[0.70448243]]\n",
            "iteration: 2726\n",
            "loss is: [[0.67877988]]\n",
            "iteration: 2727\n",
            "loss is: [[0.67766249]]\n",
            "iteration: 2728\n",
            "loss is: [[0.69173047]]\n",
            "iteration: 2729\n",
            "loss is: [[0.72960729]]\n",
            "iteration: 2730\n",
            "loss is: [[0.66651805]]\n",
            "iteration: 2731\n",
            "loss is: [[0.66699202]]\n",
            "iteration: 2732\n",
            "loss is: [[0.66355953]]\n",
            "iteration: 2733\n",
            "loss is: [[0.69132825]]\n",
            "iteration: 2734\n",
            "loss is: [[0.69085964]]\n",
            "iteration: 2735\n",
            "loss is: [[0.66810536]]\n",
            "iteration: 2736\n",
            "loss is: [[0.67041608]]\n",
            "iteration: 2737\n",
            "loss is: [[0.6648031]]\n",
            "iteration: 2738\n",
            "loss is: [[0.668603]]\n",
            "iteration: 2739\n",
            "loss is: [[0.68276361]]\n",
            "iteration: 2740\n",
            "loss is: [[0.65136197]]\n",
            "iteration: 2741\n",
            "loss is: [[0.70509348]]\n",
            "iteration: 2742\n",
            "loss is: [[0.68761704]]\n",
            "iteration: 2743\n",
            "loss is: [[0.73888174]]\n",
            "iteration: 2744\n",
            "loss is: [[0.63449805]]\n",
            "iteration: 2745\n",
            "loss is: [[0.70278806]]\n",
            "iteration: 2746\n",
            "loss is: [[0.67220251]]\n",
            "iteration: 2747\n",
            "loss is: [[0.69733127]]\n",
            "iteration: 2748\n",
            "loss is: [[0.66877616]]\n",
            "iteration: 2749\n",
            "loss is: [[0.67651645]]\n",
            "iteration: 2750\n",
            "loss is: [[0.70931261]]\n",
            "iteration: 2751\n",
            "loss is: [[0.69518507]]\n",
            "iteration: 2752\n",
            "loss is: [[0.68990319]]\n",
            "iteration: 2753\n",
            "loss is: [[0.69668642]]\n",
            "iteration: 2754\n",
            "loss is: [[0.66503652]]\n",
            "iteration: 2755\n",
            "loss is: [[0.66406517]]\n",
            "iteration: 2756\n",
            "loss is: [[0.70156159]]\n",
            "iteration: 2757\n",
            "loss is: [[0.68607628]]\n",
            "iteration: 2758\n",
            "loss is: [[0.68004787]]\n",
            "iteration: 2759\n",
            "loss is: [[0.6365431]]\n",
            "iteration: 2760\n",
            "loss is: [[0.6615235]]\n",
            "iteration: 2761\n",
            "loss is: [[0.70024809]]\n",
            "iteration: 2762\n",
            "loss is: [[0.70796543]]\n",
            "iteration: 2763\n",
            "loss is: [[0.6956722]]\n",
            "iteration: 2764\n",
            "loss is: [[0.69224925]]\n",
            "iteration: 2765\n",
            "loss is: [[0.67530894]]\n",
            "iteration: 2766\n",
            "loss is: [[0.69936576]]\n",
            "iteration: 2767\n",
            "loss is: [[0.67365526]]\n",
            "iteration: 2768\n",
            "loss is: [[0.7217804]]\n",
            "iteration: 2769\n",
            "loss is: [[0.705734]]\n",
            "iteration: 2770\n",
            "loss is: [[0.70718011]]\n",
            "iteration: 2771\n",
            "loss is: [[0.71356081]]\n",
            "iteration: 2772\n",
            "loss is: [[0.71870623]]\n",
            "iteration: 2773\n",
            "loss is: [[0.68184982]]\n",
            "iteration: 2774\n",
            "loss is: [[0.6760855]]\n",
            "iteration: 2775\n",
            "loss is: [[0.6854541]]\n",
            "iteration: 2776\n",
            "loss is: [[0.71286561]]\n",
            "iteration: 2777\n",
            "loss is: [[0.68514756]]\n",
            "iteration: 2778\n",
            "loss is: [[0.66209573]]\n",
            "iteration: 2779\n",
            "loss is: [[0.66751852]]\n",
            "iteration: 2780\n",
            "loss is: [[0.68928325]]\n",
            "iteration: 2781\n",
            "loss is: [[0.70310745]]\n",
            "iteration: 2782\n",
            "loss is: [[0.70595429]]\n",
            "iteration: 2783\n",
            "loss is: [[0.68414457]]\n",
            "iteration: 2784\n",
            "loss is: [[0.7165683]]\n",
            "iteration: 2785\n",
            "loss is: [[0.70675715]]\n",
            "iteration: 2786\n",
            "loss is: [[0.6995773]]\n",
            "iteration: 2787\n",
            "loss is: [[0.66886433]]\n",
            "iteration: 2788\n",
            "loss is: [[0.6668677]]\n",
            "iteration: 2789\n",
            "loss is: [[0.6860228]]\n",
            "iteration: 2790\n",
            "loss is: [[0.69032925]]\n",
            "iteration: 2791\n",
            "loss is: [[0.6907717]]\n",
            "iteration: 2792\n",
            "loss is: [[0.71859305]]\n",
            "iteration: 2793\n",
            "loss is: [[0.64989051]]\n",
            "iteration: 2794\n",
            "loss is: [[0.64867441]]\n",
            "iteration: 2795\n",
            "loss is: [[0.68064589]]\n",
            "iteration: 2796\n",
            "loss is: [[0.68576849]]\n",
            "iteration: 2797\n",
            "loss is: [[0.70309777]]\n",
            "iteration: 2798\n",
            "loss is: [[0.68422624]]\n",
            "iteration: 2799\n",
            "loss is: [[0.64663432]]\n",
            "iteration: 2800\n",
            "loss is: [[0.68719274]]\n",
            "iteration: 2801\n",
            "loss is: [[0.70560832]]\n",
            "iteration: 2802\n",
            "loss is: [[0.73772823]]\n",
            "iteration: 2803\n",
            "loss is: [[0.66982121]]\n",
            "iteration: 2804\n",
            "loss is: [[0.69955731]]\n",
            "iteration: 2805\n",
            "loss is: [[0.676454]]\n",
            "iteration: 2806\n",
            "loss is: [[0.67170413]]\n",
            "iteration: 2807\n",
            "loss is: [[0.6636424]]\n",
            "iteration: 2808\n",
            "loss is: [[0.68169394]]\n",
            "iteration: 2809\n",
            "loss is: [[0.67266746]]\n",
            "iteration: 2810\n",
            "loss is: [[0.67270921]]\n",
            "iteration: 2811\n",
            "loss is: [[0.67793882]]\n",
            "iteration: 2812\n",
            "loss is: [[0.66299389]]\n",
            "iteration: 2813\n",
            "loss is: [[0.67152248]]\n",
            "iteration: 2814\n",
            "loss is: [[0.6746807]]\n",
            "iteration: 2815\n",
            "loss is: [[0.69138243]]\n",
            "iteration: 2816\n",
            "loss is: [[0.68458023]]\n",
            "iteration: 2817\n",
            "loss is: [[0.69042344]]\n",
            "iteration: 2818\n",
            "loss is: [[0.70261096]]\n",
            "iteration: 2819\n",
            "loss is: [[0.68348412]]\n",
            "iteration: 2820\n",
            "loss is: [[0.7159021]]\n",
            "iteration: 2821\n",
            "loss is: [[0.72182385]]\n",
            "iteration: 2822\n",
            "loss is: [[0.72509348]]\n",
            "iteration: 2823\n",
            "loss is: [[0.7257843]]\n",
            "iteration: 2824\n",
            "loss is: [[0.69318791]]\n",
            "iteration: 2825\n",
            "loss is: [[0.70866847]]\n",
            "iteration: 2826\n",
            "loss is: [[0.68310088]]\n",
            "iteration: 2827\n",
            "loss is: [[0.7001211]]\n",
            "iteration: 2828\n",
            "loss is: [[0.67098728]]\n",
            "iteration: 2829\n",
            "loss is: [[0.67011762]]\n",
            "iteration: 2830\n",
            "loss is: [[0.66665045]]\n",
            "iteration: 2831\n",
            "loss is: [[0.6889501]]\n",
            "iteration: 2832\n",
            "loss is: [[0.68223387]]\n",
            "iteration: 2833\n",
            "loss is: [[0.70255842]]\n",
            "iteration: 2834\n",
            "loss is: [[0.68967128]]\n",
            "iteration: 2835\n",
            "loss is: [[0.6612217]]\n",
            "iteration: 2836\n",
            "loss is: [[0.6685331]]\n",
            "iteration: 2837\n",
            "loss is: [[0.66989511]]\n",
            "iteration: 2838\n",
            "loss is: [[0.69528467]]\n",
            "iteration: 2839\n",
            "loss is: [[0.66490354]]\n",
            "iteration: 2840\n",
            "loss is: [[0.67387943]]\n",
            "iteration: 2841\n",
            "loss is: [[0.68864638]]\n",
            "iteration: 2842\n",
            "loss is: [[0.64454315]]\n",
            "iteration: 2843\n",
            "loss is: [[0.65682424]]\n",
            "iteration: 2844\n",
            "loss is: [[0.69523511]]\n",
            "iteration: 2845\n",
            "loss is: [[0.70140054]]\n",
            "iteration: 2846\n",
            "loss is: [[0.6965037]]\n",
            "iteration: 2847\n",
            "loss is: [[0.69636372]]\n",
            "iteration: 2848\n",
            "loss is: [[0.73205369]]\n",
            "iteration: 2849\n",
            "loss is: [[0.69970056]]\n",
            "iteration: 2850\n",
            "loss is: [[0.68894079]]\n",
            "iteration: 2851\n",
            "loss is: [[0.71717344]]\n",
            "iteration: 2852\n",
            "loss is: [[0.68762176]]\n",
            "iteration: 2853\n",
            "loss is: [[0.71222416]]\n",
            "iteration: 2854\n",
            "loss is: [[0.6683487]]\n",
            "iteration: 2855\n",
            "loss is: [[0.70954397]]\n",
            "iteration: 2856\n",
            "loss is: [[0.67564662]]\n",
            "iteration: 2857\n",
            "loss is: [[0.68433299]]\n",
            "iteration: 2858\n",
            "loss is: [[0.64337765]]\n",
            "iteration: 2859\n",
            "loss is: [[0.68817972]]\n",
            "iteration: 2860\n",
            "loss is: [[0.69825059]]\n",
            "iteration: 2861\n",
            "loss is: [[0.68046676]]\n",
            "iteration: 2862\n",
            "loss is: [[0.69629942]]\n",
            "iteration: 2863\n",
            "loss is: [[0.70213648]]\n",
            "iteration: 2864\n",
            "loss is: [[0.72932444]]\n",
            "iteration: 2865\n",
            "loss is: [[0.68680376]]\n",
            "iteration: 2866\n",
            "loss is: [[0.69519103]]\n",
            "iteration: 2867\n",
            "loss is: [[0.71975444]]\n",
            "iteration: 2868\n",
            "loss is: [[0.68498341]]\n",
            "iteration: 2869\n",
            "loss is: [[0.68843174]]\n",
            "iteration: 2870\n",
            "loss is: [[0.70484606]]\n",
            "iteration: 2871\n",
            "loss is: [[0.68052164]]\n",
            "iteration: 2872\n",
            "loss is: [[0.67273203]]\n",
            "iteration: 2873\n",
            "loss is: [[0.70482194]]\n",
            "iteration: 2874\n",
            "loss is: [[0.69535271]]\n",
            "iteration: 2875\n",
            "loss is: [[0.70269617]]\n",
            "iteration: 2876\n",
            "loss is: [[0.68689182]]\n",
            "iteration: 2877\n",
            "loss is: [[0.70426019]]\n",
            "iteration: 2878\n",
            "loss is: [[0.68891827]]\n",
            "iteration: 2879\n",
            "loss is: [[0.65607455]]\n",
            "iteration: 2880\n",
            "loss is: [[0.69859844]]\n",
            "iteration: 2881\n",
            "loss is: [[0.64299322]]\n",
            "iteration: 2882\n",
            "loss is: [[0.66919358]]\n",
            "iteration: 2883\n",
            "loss is: [[0.67894116]]\n",
            "iteration: 2884\n",
            "loss is: [[0.70471967]]\n",
            "iteration: 2885\n",
            "loss is: [[0.66902948]]\n",
            "iteration: 2886\n",
            "loss is: [[0.64572005]]\n",
            "iteration: 2887\n",
            "loss is: [[0.63637656]]\n",
            "iteration: 2888\n",
            "loss is: [[0.66644127]]\n",
            "iteration: 2889\n",
            "loss is: [[0.70330691]]\n",
            "iteration: 2890\n",
            "loss is: [[0.64973992]]\n",
            "iteration: 2891\n",
            "loss is: [[0.70162539]]\n",
            "iteration: 2892\n",
            "loss is: [[0.69110155]]\n",
            "iteration: 2893\n",
            "loss is: [[0.66324934]]\n",
            "iteration: 2894\n",
            "loss is: [[0.70018393]]\n",
            "iteration: 2895\n",
            "loss is: [[0.66788908]]\n",
            "iteration: 2896\n",
            "loss is: [[0.68774594]]\n",
            "iteration: 2897\n",
            "loss is: [[0.6638136]]\n",
            "iteration: 2898\n",
            "loss is: [[0.67251975]]\n",
            "iteration: 2899\n",
            "loss is: [[0.67474043]]\n",
            "iteration: 2900\n",
            "loss is: [[0.68473499]]\n",
            "iteration: 2901\n",
            "loss is: [[0.71647312]]\n",
            "iteration: 2902\n",
            "loss is: [[0.68660913]]\n",
            "iteration: 2903\n",
            "loss is: [[0.63700089]]\n",
            "iteration: 2904\n",
            "loss is: [[0.69994693]]\n",
            "iteration: 2905\n",
            "loss is: [[0.6933909]]\n",
            "iteration: 2906\n",
            "loss is: [[0.68830993]]\n",
            "iteration: 2907\n",
            "loss is: [[0.6672108]]\n",
            "iteration: 2908\n",
            "loss is: [[0.6777901]]\n",
            "iteration: 2909\n",
            "loss is: [[0.6819053]]\n",
            "iteration: 2910\n",
            "loss is: [[0.67434617]]\n",
            "iteration: 2911\n",
            "loss is: [[0.64136244]]\n",
            "iteration: 2912\n",
            "loss is: [[0.68567612]]\n",
            "iteration: 2913\n",
            "loss is: [[0.71455865]]\n",
            "iteration: 2914\n",
            "loss is: [[0.682925]]\n",
            "iteration: 2915\n",
            "loss is: [[0.65069965]]\n",
            "iteration: 2916\n",
            "loss is: [[0.71771387]]\n",
            "iteration: 2917\n",
            "loss is: [[0.66909391]]\n",
            "iteration: 2918\n",
            "loss is: [[0.6749928]]\n",
            "iteration: 2919\n",
            "loss is: [[0.67032004]]\n",
            "iteration: 2920\n",
            "loss is: [[0.69026243]]\n",
            "iteration: 2921\n",
            "loss is: [[0.67402468]]\n",
            "iteration: 2922\n",
            "loss is: [[0.66226371]]\n",
            "iteration: 2923\n",
            "loss is: [[0.67678583]]\n",
            "iteration: 2924\n",
            "loss is: [[0.68840365]]\n",
            "iteration: 2925\n",
            "loss is: [[0.65634317]]\n",
            "iteration: 2926\n",
            "loss is: [[0.70127404]]\n",
            "iteration: 2927\n",
            "loss is: [[0.68341893]]\n",
            "iteration: 2928\n",
            "loss is: [[0.63595517]]\n",
            "iteration: 2929\n",
            "loss is: [[0.69002373]]\n",
            "iteration: 2930\n",
            "loss is: [[0.66316663]]\n",
            "iteration: 2931\n",
            "loss is: [[0.68756479]]\n",
            "iteration: 2932\n",
            "loss is: [[0.64910515]]\n",
            "iteration: 2933\n",
            "loss is: [[0.65314036]]\n",
            "iteration: 2934\n",
            "loss is: [[0.66451167]]\n",
            "iteration: 2935\n",
            "loss is: [[0.68236487]]\n",
            "iteration: 2936\n",
            "loss is: [[0.64502542]]\n",
            "iteration: 2937\n",
            "loss is: [[0.64236884]]\n",
            "iteration: 2938\n",
            "loss is: [[0.64838928]]\n",
            "iteration: 2939\n",
            "loss is: [[0.67209792]]\n",
            "iteration: 2940\n",
            "loss is: [[0.67542234]]\n",
            "iteration: 2941\n",
            "loss is: [[0.67117525]]\n",
            "iteration: 2942\n",
            "loss is: [[0.66510834]]\n",
            "iteration: 2943\n",
            "loss is: [[0.64947014]]\n",
            "iteration: 2944\n",
            "loss is: [[0.72573373]]\n",
            "iteration: 2945\n",
            "loss is: [[0.71387876]]\n",
            "iteration: 2946\n",
            "loss is: [[0.66318044]]\n",
            "iteration: 2947\n",
            "loss is: [[0.67040474]]\n",
            "iteration: 2948\n",
            "loss is: [[0.69577102]]\n",
            "iteration: 2949\n",
            "loss is: [[0.69331803]]\n",
            "iteration: 2950\n",
            "loss is: [[0.68241038]]\n",
            "iteration: 2951\n",
            "loss is: [[0.6812915]]\n",
            "iteration: 2952\n",
            "loss is: [[0.68141643]]\n",
            "iteration: 2953\n",
            "loss is: [[0.69745613]]\n",
            "iteration: 2954\n",
            "loss is: [[0.68995183]]\n",
            "iteration: 2955\n",
            "loss is: [[0.69592553]]\n",
            "iteration: 2956\n",
            "loss is: [[0.6988014]]\n",
            "iteration: 2957\n",
            "loss is: [[0.64998987]]\n",
            "iteration: 2958\n",
            "loss is: [[0.69358695]]\n",
            "iteration: 2959\n",
            "loss is: [[0.69739965]]\n",
            "iteration: 2960\n",
            "loss is: [[0.62775088]]\n",
            "iteration: 2961\n",
            "loss is: [[0.69259631]]\n",
            "iteration: 2962\n",
            "loss is: [[0.6964055]]\n",
            "iteration: 2963\n",
            "loss is: [[0.67622048]]\n",
            "iteration: 2964\n",
            "loss is: [[0.6811629]]\n",
            "iteration: 2965\n",
            "loss is: [[0.68551523]]\n",
            "iteration: 2966\n",
            "loss is: [[0.64963235]]\n",
            "iteration: 2967\n",
            "loss is: [[0.67059833]]\n",
            "iteration: 2968\n",
            "loss is: [[0.67442131]]\n",
            "iteration: 2969\n",
            "loss is: [[0.63257741]]\n",
            "iteration: 2970\n",
            "loss is: [[0.68317724]]\n",
            "iteration: 2971\n",
            "loss is: [[0.65251892]]\n",
            "iteration: 2972\n",
            "loss is: [[0.67153669]]\n",
            "iteration: 2973\n",
            "loss is: [[0.65401444]]\n",
            "iteration: 2974\n",
            "loss is: [[0.64801239]]\n",
            "iteration: 2975\n",
            "loss is: [[0.66851697]]\n",
            "iteration: 2976\n",
            "loss is: [[0.68454049]]\n",
            "iteration: 2977\n",
            "loss is: [[0.70127901]]\n",
            "iteration: 2978\n",
            "loss is: [[0.649939]]\n",
            "iteration: 2979\n",
            "loss is: [[0.72665723]]\n",
            "iteration: 2980\n",
            "loss is: [[0.71342919]]\n",
            "iteration: 2981\n",
            "loss is: [[0.67224184]]\n",
            "iteration: 2982\n",
            "loss is: [[0.67887274]]\n",
            "iteration: 2983\n",
            "loss is: [[0.68491514]]\n",
            "iteration: 2984\n",
            "loss is: [[0.69480755]]\n",
            "iteration: 2985\n",
            "loss is: [[0.67638501]]\n",
            "iteration: 2986\n",
            "loss is: [[0.70337228]]\n",
            "iteration: 2987\n",
            "loss is: [[0.7230273]]\n",
            "iteration: 2988\n",
            "loss is: [[0.6952582]]\n",
            "iteration: 2989\n",
            "loss is: [[0.68681848]]\n",
            "iteration: 2990\n",
            "loss is: [[0.68733383]]\n",
            "iteration: 2991\n",
            "loss is: [[0.68084662]]\n",
            "iteration: 2992\n",
            "loss is: [[0.66495294]]\n",
            "iteration: 2993\n",
            "loss is: [[0.71104947]]\n",
            "iteration: 2994\n",
            "loss is: [[0.68431958]]\n",
            "iteration: 2995\n",
            "loss is: [[0.6880325]]\n",
            "iteration: 2996\n",
            "loss is: [[0.72805615]]\n",
            "iteration: 2997\n",
            "loss is: [[0.70565105]]\n",
            "iteration: 2998\n",
            "loss is: [[0.68945798]]\n",
            "iteration: 2999\n",
            "loss is: [[0.69440926]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJXRkzvzSGDR"
      },
      "source": [
        "scaled_x_test = scaled_x_test.reshape([-1,784])\n",
        "result = np.zeros([scaled_x_test.shape[0],10])\n",
        "for pair,model in zip(pairs,model_list):\n",
        "    w = model.get('weight')\n",
        "    b = model.get('bias')\n",
        "    test_pred = (np.dot(scaled_x_test,w)+b)\n",
        "    result[(test_pred<0).flatten(),pair[1]]+=1\n",
        "    result[(test_pred>0).flatten(),pair[0]]+=1\n",
        "    \n",
        "label_result = np.argmax(result,axis=1)\n",
        "correct_num = np.sum(label_result==y_test)\n",
        "acc=correct_num/label_result.shape[0]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCu52xE6VbIM"
      },
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix(label_result, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYjSiW8EVrGv",
        "outputId": "2aabc093-0b54-4c26-cf4e-815beb5f71d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "confu = np.array([[950,0,13,4,1,6,12,2,7,14],\n",
        "[0,1115,21,4,10,20,3,37,23,11],\n",
        "[1,2,873,18,5,5,11,24,8,4],\n",
        "[1,3,18,892,0,43,0,0,26,9],\n",
        "[0,0,20,0,867,16,8,13,8,34],\n",
        "[12,2,1,35,0,760,19,0,31,10],\n",
        "[10,4,24,7,12,18,901,0,17,1],\n",
        "[2,0,19,15,2,6,0,903,11,19],\n",
        "[4,9,36,26,4,12,4,7,819,8],\n",
        "[0,0,7,9,81,6,0,42,24,899]])\n",
        "    \n",
        "plot_confusion_matrix(cm           = confu, \n",
        "                      normalize    = False,\n",
        "                      target_names = ['0', '1', '2','3','4','5','6','7','8','9'],\n",
        "                      title        = \"Confusion Matrix for Linear SVM\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}